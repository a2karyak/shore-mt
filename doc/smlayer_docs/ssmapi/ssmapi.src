\documentstyle[html,titlepage,shore]{article}
\pagestyle{plain}
\makeindex
\sloppy

\title{The Shore Storage Manager Programming Interface\thanks{
This research is sponsored
by the Advanced Research Project Agency, ARPA order number 018 (formerly
8230), monitored by the U.S. Army Research Laboratory under contract
DAAB07-92-C-Q508.
Further funding for this work was provided by DARPA through Rome
Research Laboratory Contract No. F30602-97-2-0247.
}}
\author{The Shore Project Group \\
Computer Sciences Department \\
UW-Madison \\
Madison, WI \\
\shoreversion \\
\shorecopyright
}
\date{\today}

\begin{document}
\label{ssmapi:TOP}
\maketitle
\tableofcontents
\pagebreak

\externallabels{}{../../labels.pl}
\externallabels{../ssmapi}{labels.pl}

\SHsection{ssmapi:intro}{Introduction}

The Shore Storage Manager (SSM)
is a package of libraries
for building object repository servers and their clients.
The core library in the package,
{\tt libsm.a}, is a multi-threaded system managing persistent
storage and caching of un-typed data and indexes.  It provides disk and
buffer management, transactions, concurrency control and recovery.
A second library, {\tt libshorecommon.a}, provides many common
utilities need for implementing both client and servers.  The third
library, {\tt librpclib.a}, is a slightly modified version (for use
in a multi-threaded environment) of the Sun RPC package.

We use the term {\em value-added-server} (VAS) to refer to systems
built with the SSM.  A VAS relies on the SSM for the above capabilities
and extends it to provide more functionality.  One example of a VAS is
the Shore server, which extends the SSM to provide typed objects with
permissions and ownership and organizes storage as a tree structured
name-space.  The overall role of the SSM in Shore is further described
in \htmldoclink{Shoring Up Persistent Applications}{overview.html}.

This document provides an overview the SSM facilities and interface.
Details of the programming interfaces are presented in a set of manual
pages.  Where each facility is discussed, references are made to the
appropriate manual pages.  The introductory sections for these manual
pages are:

\begin{itemize}
\item
\htmlmanlink{Storage Manager proper}{intro.ssm.html}
\item
\htmlmanlink{Thread package}{intro.sthread.html}
\item
\htmlmanlink{Common utility classes}{intro.common.html}
\item
\htmlmanlink{Foundation classes}{intro.fc.html}
\end{itemize}

The tutorial,
\htmldoclink{Writing Value-Added Servers with the Shore Storage Manager}
{ssmvas.html}, complements this document by explaining how to use
the SSM to build an example client-server system.

The rest of this document is organized as follows.  The first six
sections describe the basic facilities provided by the SSM.
Each sections has pointers to manual pages with details on using
the facility.  The final section describes how to write and compile
a VAS and its clients.

\SHsubsection{ssmapi:conventions}{Conventions}
This document follows these notational conventions: 
\begin{itemize}
\item 
File and path names are displayed in a {\tt fixed size font}.
The symbol, {\tt SHROOT}, indicates the root directory of the
Shore software installation.
\item
Reference to manual pages look like: \htmlmanlink{intro(ssm)}{intro.ssm.html}.
\item
Name of classes and methods are displayed in a {\tt fixed size font}.
\end{itemize}

\SHsection{ssmapi:initshut} {Initialization and Shutdown}

The class {\tt ss\_m} is the core of the SSM interface.  Creating an
instance of {\tt ss\_m} starts the SSM.  Destroying the {\tt ss\_m}
instance causes the SSM to shutdown.  Details on initialization and
shutdown are available in \htmlmanlink{init(ssm)}{init.ssm.html}.

When the SSM is started, it processes configuration options described
below an initialized all the SSM data structures.  This
initialization includes allocation of the buffer pool. The buffer pool
is located in shared memory, so the operating system must have
shared-memory support to accommodate the size of the buffer pool.
Next, the SSM checks the log to see if recovery is needed.
If so, it follows the steps discussed in
\hyperref{the recovery section below}{Section}{}{ssmapi:recovery}.

\SHsubsection{ssmapi:config:options} {Setting SSM Configuration Options}

The SSM has a number of configuration options that must be set before
it is started with the {\tt ss\_m} constructor. 
These options include such things as buffer pool sizes and location
of the log.  Many have default values.  Those without default
values must be set or the SSM will fail.
Below we list all options and their default values.
\begin{itemize}
\item sm\_bufpoolsize {\tt no-default}

This is the size of buffer pool in K-bytes.  The minimum value is 64.
Increasing the size will usually lower the amount of I/O done by
the SSM.

\item sm\_logdir {\tt no-default}

The SSM currently uses OS files for log storage.  This option sets
the path name of the directory where log files will be placed.

\item sm\_logsize {\tt 10000}
This is the maximum size, in K-bytes, of the log.  All updates
by transactions are logged, so the log size puts a limit
on how much work any transaction can do.  See
\hyperref {the section on logging} {Section}{}{ssmapi:logging}
for a discussion of log space usage.

\item sm\_logging {\tt yes}

This options controls whether or not logging is performed at all.
Turning it off, by setting it to {\tt no}, is used primarily for
evaluating logging performance.  No recovery or transaction rollback
can be performed if logging is off.

\item sm\_diskrw {\tt diskrw}

This is the path name of the program forked by the SSM to perform
asynchronous I/O.  Usually this will point to {\tt bin/diskrw}
where Shore is installed.

\item sm\_locktablesize {\tt 64000}

This is the number of buckets in the hash table used by the lock
manager.  

\item sm\_backgroundflush {\tt yes}

This option controls whether or not there is
a background thread started to
flushing the buffer pool periodically.

\item sm\_errlog {\tt - (stderr)}

This is the location to send error logging messages.  The
default is the standard error file.    Other options
are {\tt syslogd} (to syslog daemon), or to a specific filename.

\item sm\_errlog\_level {\tt error}

This is the level of error logging detail.
Possible values (from least amount of logging to most amount)
are {\tt none emerg fatal alert internal error warning info debug}.
\end{itemize}

\SHsubsection{ssmapi:options} {Adding VAS-Specific Options}

In addition, a VAS, will often have options of its own that need
to be set.  The SSM provides an options facility,
\htmlmanlink {options(common)} {options.common.html} for this purpose.
Included with the option facility are functions to set options from
the program command line and from files containing configuration
information.

\htmlextref{A discussion of how to use the options
facility}{ssmvas:config} is given in the tutorial.


\SHsection{ssmapi:storage}{Storage Facilities}

The SSM provides a hierarchy of storage structures.  A description
of each type of storage structure is given below, followed by
a description of the identifiers used to refer to them.

\SHsubsection{ssmapi:devices} {Devices}

A {\em device} is a location, provided by the operating system, for
storing data.  In the current implementation, a device is either a
disk partition or an operating system file.  A device is identified by
the name used to access it through the operating system.  Each device
is managed by a single server.  A device has a quota.  The sum of the
quotas of all the volumes on a device cannot exceed the device quota.
{\em Note}: devices are currently limited to containing only one volume.

The device management interface is part of class {\tt ss\_m}
and is described in
\htmlmanlink{device(ssm)}{device.ssm.html}.

For each mounted device, the server forks a process called {\tt diskrw}
(determined by the {\tt sm\_diskrw} option) to perform asynchronous
I/O on the device.  These processes communicate with the server
through sockets and shared memory, so your OS must be configured
with shared memory support.

\SHsubsection{ssmapi:volumes} {Volumes}

A {\em volume} is a collection of file and index storage structures
(described below) managed as a unit.  All storage structures reside
entirely on one volume.  A volume has a quota specifying how
must large it can grow.
Every volume has a dedicated 
\htmlextref {B+-tree index}{ssmapi:btree}, called the {\em root index}
to be used for cataloging the data on the volume.

The volume management interface is part of class {\tt ss\_m}
and is described in
\htmlmanlink{volume(ssm)}{volume.ssm.html}.

\SHsubsection{ssmapi:files} {Files of Records}

A {\em record} \footnote {The term record is used to distinguish them
from objects (which have type and methods).} is an un-typed container
of bytes, consisting of a {\em tag}, {\em header} and {\em body}.
The tag is a small, read-only location that stores the record size
and other implementation-related information.  The header is variable
length (limited to what will fit on a page) location for a VAS to
store meta-information about the record (such as its type).  The body
is the primary data storage location and can range in size from zero
bytes to 4-GB.  A record can grow and shrink in size by operations
that append and truncate bytes at the end of the record.

A {\em file} is a collection of records.  Files are used for
clustering records and have an interface for iterating over all the
records they contain.  The number of records that a file can hold is
limited only by the space available on the volume containing the file.
The minimum size of a file is 64K-bytes (8 pages).  We are working on
ways to reduce this to 8K, but in either case, using a file to store
a collection containing only a few small records will waste space.

Methods for creating/destroying files and creating/destroying/modifying
records are part of class {\tt ss\_m} and described in
\htmlmanlink{file(ssm)}{file.ssm.html}.
There is a {\tt pin\_i} class for
pinning records for reading and modifying.  This class is
documented in \htmlmanlink{pin\_i(ssm)}{pin_i.ssm.html}.
There are the classes 
{\tt scan\_file\_i} for iterating over the records in a file,
and 
{\tt append\_file\_i} for appending records to a file.
Both are described in 
\htmlmanlink{scan\_file\_i(ssm)}{scan_file_i.ssm.html}.

\SHsubsection{ssmapi:btree} {B+tree Indexes}

The {\em B+tree index} facility provides associative access to data.
Keys and their associated values can be variable length (up to the
size of a page).  Keys can be composed of any of the basic C-language types plus
variable length character strings.  A bulk-loading facility is provided.
The number of key-value pairs that an index can hold is limited only
by the space available on the volume containing the index.  The minimum
size of a B+tree index is 8K-bytes (1 page).

Methods for index operations are part of class
{\tt ss\_m} and described in
\htmlmanlink{btree(ssm)}{btree.ssm.html}.
There is {\tt scan\_index\_i} class for iterating over 
a range of keys in the index
This class is documented in
\htmlmanlink{scan\_index\_i(ssm)}{scan_index_i.ssm.html}.

\SHsubsection{ssmapi:rtree} {R*Tree Indexes}

An {\em R-Tree} is a height-balanced tree structure designed specifically 
for indexing multi-dimensional spatial objects. It stores the 
{\em minimum bounding box} (with 2 or higher dimension) of a spatial object
as the key in the leaf pages.  The current implementation in SHORE is
a variant of R-Tree called {\em R*-Tree}
\cite{bk:rtree}, which improves the search
performance by using a better heuristic for redistributing entries 
and dynamically reorganizing the tree during insertion.
Currently, only 2-dimensional R*-trees with integer coordinates
are supported by the SSM.
A bulk-loading facility is provided.
The number of key-value pairs that an index can hold is limited only 
by the space available on the volume containing the index.
The minimum size of an R*tree index is 64K-bytes (8 pages).

The R*-Tree implementation stores [key, value] pairs, where
the key is of type
\htmlmanlink{{\tt nbox\_t}}{nbox_t.common.html}.
and the value is of type
\htmlmanlink{{\tt vec\_t}}{vec_t.common.html}. A 2-D {\tt nbox\_t} is a
rectangle which stores coordinates in the order of x\_low, y\_low,
x\_high, y\_high (lower left point and higher right point). Currently,
only  integer values are supported for the coordinates.

Methods for R*-tree index operations are part of class
{\tt ss\_m} and described in
\htmlmanlink{rtree(ssm)}{rtree.ssm.html}.
There is {\tt scan\_rt\_i} class for iterating over 
a range of keys in the index
This class is documented in
\htmlmanlink{scan\_rt\_i(ssm)}{scan_rt_i.ssm.html}.


\SHsubsection{ssmapi:identifiers} {Identifiers}

Volumes, files, records and indexes all have identifiers.
There are two broad categories of identifiers: {\em logical} and
{\em physical}.  Logical IDs are location-independent meaning
there is a level of indirection for mapping the ID to a physical
location.  Physical IDs are location-dependent, meaning they
refer to the physical location (usually location on disk) of the
referenced object.
{\em Although the SSM has both physical and logical ID versions of its
interface, only the version using logical IDs is supported at this
time}.

Volume IDs are a globally unique, 8-byte long ID
called {\tt lvid\_t} described in 
\htmlmanlink{{\tt lid\_t(common)}} {lid_t.common.html}.
File, record and index IDs are identified by a serial number,
\htmlmanlink{{\tt serial\_t}} {serial_t.common.html},
unique to the volume containing them.
Serial numbers are currently 4 bytes long, but we plan to make
them 8 bytes long in the future.
The complete ID for a file, index or record is a combination
of the volume ID and serial number call {\tt lid\_t} and described
in
\htmlmanlink{lid\_t(common)}{lid_t.common.html}.
Once the object a serial number identifies is destroyed, the
serial number will never be reused.

The purpose of having two-part IDs (volume ID, serial number) is to
allow {\em local} (ie. intra-volume) references to be stored using
only the serial number.  This can significantly reduce the size
of databases containing records with lots of pointers.  To keep
{\em remote} (ie. inter-volume) references just as short, special serial
numbers for remote references are used.

Methods for operating on IDs and generating remote references
are described in \htmlmanlink{lid(ssm)}{lid.ssm.html}.

\SHsection{ssmapi:transaction} {Transaction Facilities}

As a database storage engine, the SSM provides the atomicity,
consistency, isolation, and durability (often referred to as ACID)
properties associated with transactions.
More information on transaction processing issues can be found
in the book {\em Transaction Processing: concepts and techniques}
\cite{gr:tra}.

\SHsubsection{ssmapi:xact} {Transactions}

A transaction bounds an atomic and set of operations
on records, files, and indexes.  The manual page,
\htmlmanlink{transaction(ssm)}{transaction.ssm.html}, describes methods
for beginning, committing and aborting transactions.  Updates made
by committed transactions are guaranteed to be reflected on stable
storage, even in the event of software or processor failure. Updates
made by aborted transactions are rolled back and are not reflected on
stable storage.

Although nested transactions are not provided at this time, the notion
of save-points are.  Save-points delineate a set of operations that can be
rolled back without rolling back the entire transaction.  The interface
is described in \htmlmanlink{transaction(ssm)}{transaction.ssm.html}.

\SHsubsection{ssmapi:concurrency} {Concurrency Control}

Transactions are also a unit if isolation.  Locking is provided
by the SSM as a way to keep one transaction from interfering with
another.  When designing the SSM interface there was considerable
debate on whether the SSM should automatically do locking 
or instead require the VAS writer to obtain appropriate locks.
We chose to have the SSM automatically obtain locks, but the SSM
interface does provide methods allowing locks to be explicitly
acquired.  See \htmlmanlink{lock(ssm)}{lock.ssm.html} for details.

The SSM performs concurrency control using the standard hierarchical
two-phase locking protocol \cite{gr:tra}.  The lock hierarchy for files
is: volume, file, page, slot-containing-record.  The lock hierarchy
for indexes is: volume, index, key-value.

Chained transactions are also provided.  Chaining involves committing
a transaction, retaining its locks, starting a new transaction
and giving the locks to the new transaction.


\SHsection{ssmapi:xact} {Crash Recovery Facilities}

The crash recovery facilities of the SSM can be divided into:
logging, checkpointing, and recovery management.  

\SHsubsection{ssmapi:logging} {Logging}

Updates performed by transactions are logged so that
the can be rolled back (in the event of a transaction abort)
or restored (in the event of a crash).  Both the old and new values
of an updated location are logged.  This allows a steal, no-force
buffer management policy, which means the buffer manager is free
to write dirty pages to disk at any time and yet does not have
to write dirty pages for a a transaction to commit.

The log is a location holding log records.  Currently the log is stored
in Unix files in a special directory (we plan to support using a raw
device partition in the future).  The size and location of the
log is determined by configuration options described in
\hyperref {the initialization section above} {Section}{}{ssmapi:initshut}.

The proper value for the size of the log depends upon the
expected transaction mix.  More specifically, it depends on the
age of the oldest (longest running) transaction in the system and
the amount of log space used by all active transactions. Here are
some general rules to determine the  amount  of  free  log  space
available in the system.

\begin{itemize}
\item  Log records between the first log
     record generated by the oldest active transaction and the most
     recent log record generated by any transaction cannot be thrown
     away.

\item  Log records from a transaction are no longer needed
   once the transaction has committed or completely aborted and all
   updates have made it to disk. Aborting a transaction causes log space
   to be used, so space is reserved for aborting each transaction.
   Enough log space must be available to commit or abort all active
   transactions at all times.

\item  Only space starting at the beginning of the log can be
   reused.  This space can be reused if it contains log
   records only for transactions meeting the previous rule.

\item  All {\tt ss\_m} calls that update records require log space twice
   the size of the space updated in the record. All calls that create,
   append, or truncate records require log space equal to the size
   created, inserted, or deleted. Log records generated by these calls
   (generally one per call) have an overhead of approximately 50 bytes.

\item  The amount of log space reserved for aborting a transaction is
   equal to the amount of log space generated by the transaction.

\item  When insufficient log space is available for a transaction,
   the transaction is aborted.

\item  The log should be at least 1 Mbyte.
\end{itemize}

For example, consider a transaction T1 that creates 300 records
of  size 2,000 bytes, writes 20 bytes in 100 objects, and is
committed. T1 requires at 615 Kbytes for the creates and 9 Kbytes
of log  space  for  the  writes.  Since log space must be reserved to
abort the transaction, the log size must be over 1.248 Mbytes  to run
this transaction. Assuming T1 is the only transaction running in the
system, all the log space it  uses  and  reserves  becomes available
when  it  completes.   If  another transaction, T2, is started at the
same time as T1, but is still running after T1  is committed,  only the
reserved space for T1 is available for other transactions.  The portion
of the log used by T1 and  T2  is  not available until T2 is finished.

Transactions that fail because of insufficient log space are commonly
those that load a large number of objects into a file during the
creation of a database. A solution to this problem is  to load  the
file in a series of smaller transactions. When the last transaction
is committed, the load is complete. If the load needs to be aborted,
a separate transaction is run to destroy the file.

\SHsubsection{ssmapi:checkpoints} {Checkpointing}

Checkpoints are taken periodically by the SSM in order to free log
space and shorten recovery time.  Checkpoints are ``fuzzy'' and can
do not require the system to pause while they are completing.

\SHsubsection{ssmapi:recovery} {Recovery}

The SSM recovers from software, operating system,
and CPU failure by restoring updates made by committed transactions
and rolling back all updates by transactions that did not commit by
the time of the crash.
when an instance of class {\tt ss\_m} is created.

Recovery has three phases:
\begin{itemize}
\item Analysis

During the analysis phase the log is scanned to determine what
transactions were active and which devices were mounted at the
time of the failure.

\item Redo

During the redo phase the devices are remounted and the log is
scanned starting at a location determined by analysis.
The operation recorded in each log record is redone if necessary.
After redo, the database is in the state it was just before the crash.

\item Undo

During the undo phase, all active transactions at the time of the crash
are undone.  The devices are dismounted, and a checkpoint is taken.


\end{itemize}

The time it takes for recovery depends on several
factors, including the number of transactions in progress at  the
time of the failure, the number of log records generated by these
transactions, and the number of log records generated  since  the
last checkpoint.


\SHsection{ssmapi:threads} {Thread Management}

Providing the facilities to implement a multi-threaded
server capable of managing multiple transactions is one of the
distinguishing features of the SSM.  Other persistent storage
systems such as the \htmladdnormallink{Exodus Storage Manager
(http://www.cs.wisc.edu/exodus/)} {http://www.cs.wisc.edu/exodus/})
only support writing clients that run one transaction at a time
and are usually single-threaded.

The Shore Thread Package is documented in
\htmlmanlink{intro(sthread)}{intro.sthread.html}
All threads are derived from the abstract base class {\tt sthread\_t}.  
Any thread that uses the SSM facilities must be derived from
class {\tt smthread\_t} described in 
\htmlmanlink{smthread\_t(ssm)}{smthread_t.ssm.html}

\htmlextref{A discussion of how to use threads
facility}{ssmvas:threadmgmt} is given in the tutorial.

Any program using the thread package automatically has
one thread, the one running {\tt main()}.
In addition, the SSM starts one thread to do background flushing
of the buffer pool and another to take periodic checkpoints.

We have also implemented some extensions to the thread package.
These are not formally part of the thread package, but we've found
them useful enough in building the SSM and the Shore VAS to warrant
including them as part of the documented interface.

\SHsubsection{ssmapi:latch} {Latches}

Latches are a read/write synchronization mechanism for threads,
as opposed to locks which are used for synchronizing transactions.
Latches are much lighter weight than locks, have no symbolic names,
and have no deadlock detection.  Latches are described in
\htmlmanlink{latch\_t(common)}{latch_t.common.html}

\SHsubsection{ssmapi:hashtable} {Thread-Protected Hash Tables}

The Resource Manager, {\tt rsrc\_m}, template class manages a fixed
size pool of {\em shared resources} in a multi-threaded environment.
The {\tt rsrc\_m} protects each resource with a latch and uses them
to enforce a protocol in which multiple threads have consistent
and concurrent access to the shared resources. For instance, the
Shore buffer manager uses rsrc\_m to manage buffer control blocks.
The {\tt rsrc\_m} is implemented using a hash table.  When a
entry needs to be added and the table is full, on old entry is
removed based on an LRU policy.  More details can be found in
\htmlmanlink{rsrc(common)}{rsrc.common.html}

\SHsection{ssmapi:errorhandling} {Error Handling}

Errors in the SSM (and the rest of Shore) are indicated by an
unsigned integer encapsulated in a class that includes stack
traces and other debugging aids.
The class is {\tt w\_rc\_t} (commonly {\tt typdef}ed 
to {\tt rc\_t}) described in
\htmlmanlink{rc(fc)}{rc.fc.html}.  It is the return type
for most SSM methods.  When linking with a debugging version of the SSM
(compiled with {\tt \#define DEBUG}), the destructor of an {\tt w\_rc\_t}
object performs auditing to verify that it was checked at least once.
If not checked, the destructor calls {\tt w\_rc\_t::error\_not\_checked}
which prints a warning message.  An {\tt w\_rc\_t} is considered checked
when any of its methods that read/examine the error code are called,
including the assignment operator.  Therefore, simply returning an {\tt
w\_rc\_t} (which involves an assignment) is considered checking it.
Of course, the newly assigned {\tt w\_rc\_t} is considered unchecked.

The domain of error codes is an extension of the Unix error codes
found in {\tt \#include <errno.h>}.  Each layer of the Shore software
adds its own extension to the domain.  The following layers have error
codes which may be returned by SSM methods:
\begin{itemize}
\item Storage Manager proper, see
\htmlmanlink{errors(ssm)}{errors.ssm.html}.
\item Thread package, see
\htmlmanlink{errors(sthread)}{errors.sthread.html}.
\item Configuration options package, see
\htmlmanlink{options(common)}{options.common.html}.
\item Foundation Classes, see
\htmlmanlink{intro(fc)}{intro.fc.html}.
\end{itemize}

\htmlextref{Further discussion of error handling}{ssmvas:errors} is
given in the tutorial.

VAS writers may wish to use the error handling facility to add there
own error codes.  See \htmlmanlink{error(fc)}{error.fc.html} for
more details.


\SHsection{ssmapi:rpc} {Communication and RPC Facilities}

Clients (applications) need a way to communicate with servers.
The release of the SSM does not contain any communication or
RPC facilities for client-server communication.
However, the {\shoreversion} release contains
a version of the publicly available Sun RPC
package, modified to operate with the SSM's thread package.
The Shore value-added server uses this package.  The tutorial
contains an
\htmlextref{example of using the RPC package}{ssmvas:rpc}
and a
\htmlextref{discussion of its integration with the thread package}
{ssmvas:multithread2}.

One of the goals of Shore is that clients only need to communicate
with a server on their local machine.  The SSM in the local server
\htmlextref{cooperates with other remote SSMs}{overview:peer} to
cache data locally.  Our work on this capability is not complete.
Eventually, the communication system we built to support this will
also be available to VAS writers.


\SHsection{ssmapi:util} {Miscellaneous Facilities}

\SHsubsection{ssmapi:statistics} {Statistics}

The SSM keeps many statistics on its operation such as
lock request and page I/O counts.  Details are available in 
\htmlmanlink{statistics(ssm)}{statistics.ssm.html}.
A utility for 
formatted printing of these statistics is described in
\htmlmanlink{statistics(fc)}{statistics.fc.html}.

\SHsubsection{ssmapi:Sorting} {Sorting}

The SSM has sorting facilities, however they are still
under development, so the interface may change.  Descriptions
of the sorting facilities can be found in
\htmlmanlink{sort\_stream\_i(ssm)}{sort_stream_i.ssm.html}
and
\htmlmanlink{sort(ssm)}{sort.ssm.html}

\SHsubsection{ssmapi:vector} {Data Vectors}

A data vector is an array of pointers-length pairs to in-memory data.
The array can be arbitrarily long, and methods are provided
to comparing and copying data.
They are further described in
\htmlmanlink{vec\_t(common)}{vec_t.common.html}.

Data vectors reduce the number of parameters in 
many SSM methods be combining pointer and length information.
More importantly, they allow more flexibility in structuring
data.  For example, consider record that is stored in
memory in three parts.  To create the record, all that
is necessary is to build a vector pointing to the three parts
and pass the vector to the {\tt ss\_m::create\_rec} method.


\SHsection{ssmapi:vas}{Writing and Compiling a VAS and Client}

This section discusses some of the general issues in compiling and
linking with the SSM libraries.  Still, the best way to learn about
writing and compiling a VAS and client is to read the tutorial,
\htmldoclink{Writing Value-Added Servers with the Shore Storage
Manager} {ssmvas.html}.

\SHsubsection{ssmapi:vasincl}{Include Files and Libraries}

All of the include files needed to build servers and clients
are located in {\tt SHROOT/include}.
Any server code using the SSM should include {\tt sm\_vas.h}.
Since clients do not need all of the SSM functionality,
they need only include {\tt sm\_app.h}.
The RPC package include files are located in {\tt SHROOT/include/rpc}
and are usually included with this line:
\begin{verbatim}
	#include <rpc/rpc.h>
\end{verbatim}

All of the libraries needed to build servers and clients
are located in {\tt SHROOT/lib}.
Clients only need {\tt libshorecommon.a}.
Servers need both {\tt libsm.a} and {\tt libshorecommon.a}
The RPC package library is {\tt librpclib.a}.

There are two pre-compiled version of these libraries.  The are
included in the {\em debugging} and {\em no-debugging} binary releases.
The debugging version not only includes symbol table information ({\tt
-g} option to {\tt gcc}), but also has considerable additional auditing
and assert checking code.  This includes code that audits data pages
whenever an update is made, performs monitoring to detect thread
stack overflow, and checks over 1,400 additional assertions.
See the
\htmlextref{Shore Release}{release:binary}
document for more information on these releases.

{\em Note:} when compiling for linkage with the debugging release, 
the compiler flag {\tt -DDEBUG} should be used.


\SHsubsection{ssmapi:template}{Template Instantiation}

The SSM uses a number of templates
One of the issues that is often confusing is controlling
template instantiation.  All of the template instantiations
needed by the SSM are already included in the libraries.

However, due to a bug in {\tt gcc} 2.6.* (supposedly to be
fixed in 2.7.0), it is possible to have problems
during linking due to multiple definitions of template code.
To avoid this, and to have smaller executables,
we use the {\tt gcc} option {\tt -fno-implicit-templates} in the
\htmlextref{{\tt Makefile}}{ssmvas:makefile}
from the tutorial example.
This causes {\tt gcc} not to emit
any template code unless the template is explicitly instantiated.

Here is an example of explicit instantiation from the tutorial
\begin{verbatim}
    #ifdef __GNUG__
    // Explicitly instantiate lists of client_t.
    template class w_list_t<client_t>;
    #endif
\end{verbatim}

\SHsubsection{ssmapi:vasex}{Other Example Code}

The SSM has been used to build a number of value-added servers.  Some of
these are publicly available.  You may
find these helpful in writing your own.

\begin{itemize}
\item Shore Server

The Shore Server is the server for the Shore object repository.
The Shore Server actually has two interfaces.  One is used
by SDL applications and the other is the NFS interface.
The Shore Server code is available in {\tt src/vas}. 

\item SSM Testing Shell 

The SSM testing shell is a server with a TCL interface designed to
test the SSM.  The code is available in {\tt src/sm/ssh}.
No documentation is available yet.

\item Paradise

Paradise is a GIS system still under development.  It will be 
publicly available in the future.  See 
\htmladdnormallink{http://www.cs.wisc.edu/paradise/}
{http://www.cs.wisc.edu/paradise/} 
for more information.

\end{itemize}

\begin{thebibliography}{1234}
\bibitem[BKSS]{bk:rtree} Beckmann, N., Kriegel, H.P., Schneider, R., Seeger, B.
``The R*{\ndash}Tree: An Efficient and Robust Access Method for Points
and Rectangles''. Proc. ACM SIGMOD Int. Conf. on Management of Data,
1990, pp. 322-331.
\bibitem[GrRe]{gr:tra} Gray, J., Reuter, A.
Transaction Processing: concepts and techniques,
1993.
\end{thebibliography}

\end{document}

