@article{aks:the,
	Author = "M. Ajtai and J. Koml\'os and E. Szemer\'edi",
	Title = "The longest path in a random graph",
	Journal = "Combinatoria",
	Volume = 1,
	Pages = "1--12"}

@inproceedings{p:pro,
	Author = "P. Raghavan",
	Title = "Probabilistic Construction of Deterministic Algorithms:
		Approximating Packing Integer Programs",
	Booktitle = "Proceedings of the 27th Annual IEEE Symposium on
		Foundations of Computer Science",
	Pages = "10--18",
	Year = 1986}

@article{rs:approx,
	Author = "J. B. Rosser and L. Schoenfeld",
	Title = "Approximate formulas for some functions of prime numbers",
	Journal = "Illinois Journal of Mathematics",
	Volume = 6,
	Pages = "64--94",
	Year = 1962} 

@article{g:ont,
	Author = "L. A. Goodman",
	Title = "On the Estimation of the Number of Classes in a
                 Population",
	Journal = "Ann. Math. Sta.",
	Year = 1949}

@unpublished{rss:gen,
	Author = "Raghu Ramakrishnan and Divesh Srivastava and 
		  S. Sudarshan",
	Title = "Generalized Semi-Naive Evaluation of Logic Programs",
	Month = "October",
	Year = 1989,
	Note = "Unpublished Manuscript, University of Wisconsin-Madison"}

@article{g:bou,
	Author = "R. Graham",
	Title = "Bounds on Multiprocessing Timing Anomalies",
	Journal = "SIAM Journal of Computing",
	Volume = 17,
	Pages = "416 -- 429",
	Year = 1969}

@article{gp:ont,
	Author = "Daniele Gardy and Claude Puech",
	Title = "On the sizes of projections: A  generating
		 function approach",
	Journal = "Information Systems",
	Volume = 9,
	Number = "3/4",
	Pages = "231--235",
	Year = 1984,
	Annote = "A virtually impenetrable paper; many key terms are
                  used without definition.  The final formulas appear
                  to be computationally infeasible.  For example, if
                  the product of the sizes of the domains of the
                  relation is d, and the size of the relation is
                  l, their formula requires the computation of
                  $d \choose l$."}
	

@inproceedings{apprsu:con,
	Author = "F. Afrati and C. H. Papadimitriou and G. Papageorgiou
		  and A. Roussou and Y. Sagiv and J. D. Ullman",
	Title = "Convergence of sideways query evaluation",
	Booktitle = "Proceedings of the Fifth ACM 
		     Symposium on Principles of Database Systems",
	Year = 1986,
	Pages = "24--30",
	Address = "Cambridge, Massachusetts",
	Month = "March",
	Annote = "No note."}

@inproceedings{a:alp,
	Author = "Rakesh Agrawal",
	Title = "Alpha: An Extension of Relational Algebra
	         to Express a Class of Recursive Queries",
	Booktitle = "Proceedings of the IEEE Conference on Data Engineering",
	Month = "February",
	Address = "Los Angeles, Californaia",
	Pages = "580--590",
	Year = 1987}

@inproceedings{aj:dir,
	Author = "Rakesh Agrawal and H. V. Jagadish",
	Title = "Direct Algorithms for Computing the Transitive
		 Closure of Database Relations",
	Booktitle = "Proceedings of the 13th VLDB Conference",
	Month = "September",
	Address = "Brighton, England",
	Year = 1987,
	Pages = "255--266",
	Annote = "The authors' propose two variants of Warshall's and
		  Warren's algorithms for computing transitive
		  closures.  They argue that, using disk access as
		  cost function, these methods are much better than
		  semi-naive or logarithmic.  They also note that
		  the algorithm doesn't depend on the length of
		  the longest path (it achieves this by always running
		  as long as the longest possible path!)
		  
		  I have reservations about this stuff.  First, it
		  seems to be fundamentally $n^3$, which could make it
		  bad for sparse graphs.  Secondly, it is difficult
		  to see how to use these techniques to compute portions 
		  of the transitive closure, that is, selections on closures, 
		  without first computing the entire transitive
	          closure."}

@article{abm:one,
	Author = "Rafiul Ahad and {K. V.} {Bapa Rao} and Dennis McLeod",
	Title = "On Estimating the Cardinality of the Projection of 
                 a Database Relation",
	Journal = "ACM Transactions on Database Systems",
	Month = "March",
	Year = 1989,
	Volume = 14,
	Number = 1,
	Pages = "28--40"}

@book{ahu:the,
	Author = "Alfred V. Aho and John E. Hopcroft and Jeffrey D. Ullman",
	Title = "The Design and Analysis of Computer Algorithms",
	Year = 1974,
	Publisher = "Addison-Wesley"}
	

@article{asu:equ,	
	Author = "Alfred V. Aho and Yehoshua Sagiv and Jeffrey D. Ullman",
	Title = "Equivalence of relational expressions",
	Journal = "SIAM Journal of Computing",
	Year =  1979,
	Volume = 8,
	Number = 2,
	Pages = "218--246",
	Annote = "This is the original tableaux paper.  It proves that
		  deciding equivalences of tableax in general is NP-
	 	  complete, and gives a subset of tableaux for which
		  there is a polynomial algorithm.  Also contains
		  theorems about minimizing tableaux, including the
		  fact that the minimal tableau equivalent to any
		  given tableau is a subset of the rows of that 
		  tableau."}

@inproceedings{au:uni,
	Author = "Alfred V. Aho and Jeffrey D. Ullman",
	Title = "Universality of data retrieval languages",
	Booktitle = "Proceedings of the Sixth ACM Symposium on
		     Principles of Programming Languages",
	Year = 1979,
	Pages = "110--120",
	Address = "San Antonio, Texas",
	Annote = "The authors give two principles that query languages
		  should satisfy - independence of order of tuples in
		  relations and invariant under renamings that preserve
		  order-type relations.  They show that relational algebra
		  satisfies these conditions, but misses some such
		  queries, those with a least fixed-point operator.
		  They note that optimizing such a language is harder than 
		  the normal relational algebra case.  They prove that a 
		  least fixed-point operator increases the power of the 
		  language, and suggest a language incorporating this 
		  operator.  The proof hinges upon showing that any
		  given relational algebra expression can only state 
		  conditions relating elements a constant distance apart."}

@article{an:log,
	Author = "Hassan Ait-Kaci and Roger Nasr",
	Title = "Login: a logic programming language with
		 built-in inheritance",
	Journal = "Journal of Logic Programming",
	Year = 1986,
	Volume = 3,
	Number = 3,
	Month = "October",
	Annote = "Tries to improve efficiency by including inheritance
		  by generalized unification rather than by resolution
		  and explicit rules of inheritance.  Uses lattice
		  theory, etc., to provide a typed extension of prolog 
		  with the semantics of ``type as a set.''"}

@techreport{abw:tow,
	Author = "K. R. Apt and H. Blair and A. Walker",
	Title = "Towards a theory of declarative knowledge",
	Institution = "IBM Thomas J. Watson Research Center",
	Year = 1985,
	Annote = "Haven't read this one, but apparently one
	          of the first papers to propose stratification
		  to deal with negation."}

@unpublished{bkmr:pro,
	Author = "Isaac Balbin and David B. Kemp and
                  Krishnamurthy Meenakshi and Kotagiri
		  Ramamohanarao",
	Title = "Propagating Constraints in Recursive 
		 Deductive Databases",
	Annote = "Shows how to propagate constraints such as
                  $X > 5$ through recursions by rewriting
		  (folding the constraints in as far as 
                  possible) then applying magic sets."}

	
@techreport{br:adi,
	Author = "I. Balbin and K. Ramamohanarao",
	Title = "A Differential Approach to Query Optimisation
		 in Deductive Databases",
	Institution = "Department of Computer Science, University
		       of Melbourne",
	Number = "86/7",
	Year = 1986,
	Annote = "Not read - another discovery of semi-naive evaluation."}

@article{b:alo,
	Author = "Francois Bancilhon",
	Title = "A Logic-Programming/Object-Oriented Cocktail",
	Journal = "SIGMOD Record",
	Year = 1986,
	Volume = 15,
	Number = 3,
	Pages = "11--21",
	Month = "September",
	Annote = "Notes that the object-oriented paradigm needn't
		  specify the computational model, and gives an
		  object-oriented system where queries are ``clean''
		  logic programs and updates are dirty declarative
		  programs."}
	

@incollection{b:nai,
	Author = "Francois Bancilhon",
	Title = "Naive Evaluation of Recursively Defined Relations",
	Booktitle = "On Knowledge Base Management Systems --- Integrating
		     Database and AI Systems",
	Year = 1985,
	Editor = "Brodie and Mylopoulos",
	Publisher = "Springer-Verlag"}

@inproceedings{b:ont,
	Author = "Francois Bancilhon",
	Title = "On the completeness of query languages for relational
		 databases",
	Booktitle = "Proceedings of the Seventh Symposium on Mathematical
		     Foundations of Computer Science",
	Year = 1978,
	Pages = "112-123",
	Annote = "Proves that when restricted to finite relations, 
		  for a given database relational calculus can express all 
		  and only the relations whose extension is definable over 
		  all domains of that database."}


@inproceedings{bmsu:mag,
	Author = "Francois Bancilhon and David Maier and
		  Yehoshua Sagiv and Jeffrey D. Ullman",
	Title = "Magic sets and other strange ways to implement logic
		 programs",
	Booktitle = "Proceedings of the ACM 
		     Symposium on Principles of Database Systems",
	Year = 1986,
	Month = "March",
	Address = "Cambridge, Massachusetts",
	Pages = "1--15",
	Annote = "Discusses compiled methods for evaluating recursive
		  logic programs that try to take advantage of bound
		  values to restrict the search.
	          The methods considered are Henschen and Naqvi's, magic 
		  sets, counting, and reverse counting.  The major conclusion
		  is that different methods are good for different
		  databases, and that there's no way to say one algorithm
		  is better for all."}


@inproceedings{br:per,
	Author = "Francois Bancilhon and Raghu Ramakrishnan",
	Title = "Performance Evaluation of Data Intensive
		 Logic Programs",
	Booktitle = "Foundations of Deductive Databases and 
	             Logic Programming",
	Editor = "Jack Minker",
	Publisher = "Morgan Kaufmann",
	Address = "Los Altos, California",
	Pages = "439-517",
	Year = 1988}

@inproceedings{br:ana,
	Author = "Francois Bancilhon and Raghu Ramakrishnan",
	Title = "An Amateur's Introduction to Recursive Query Processing
		 Strategies",
	Booktitle = "Proceedings of the ACM SIGMOD International Conference
		     on Management of Data",
	Year = 1986,
	Address = "Washington, D.C.",
	Month = "May",
	Pages = "16--52",
	Annote = "A survey of a bunch of methods that have
		  been published in impenetrable papers.  Tries to
		  compare the methods on the criteria of size of
		  intermediate relations.  Good bibliography.
		  
		  Their conclusion is that, given their admittedly
		  small test cases, the differences between the methods can
		  be explained by duplication, relevant facts, and
		  unary vs. binary intermediate relations."}

@techreport{b:que,
	Author = "R. Bayer",
	Title = "Query evaluation and recursion in deductive database
		  systems",
	Institution = "Technische Universitaet Muenchen",
	Month = "February",
	Year = 1985,
	Number = "18503",
	Annote = "(Not read) Another discovery of semi-naive."}

@inproceedings{b:datmodels,
	Author = "Catriel Beeri",
	Title = "Data Models and Languages for Databases",
	Booktitle = "Proceedings of the International Conference
                     on Database Theory",
	Month = "August",
	Year = 1988,
	Address = "Bruges, Belgium",
	Annote = "Tries to extend relational formalism to handle
                  object model.  Only considers structural issues.
                  Basic idea: instead of type definitions generating
                  arbitrary sets of possible values built up from
                  atomic values, use a given object structure instead.
                  This object structure associates a collection of
                  objects with each type, and a value for each object."}
	
@inproceedings{bkbr:bou,
	Author = "Catriel Beeri and Paris Kanellakis and Francois
		  Bancilhon and Raghu Ramakrishnan",
	Title = "Bounds on the Propagation of Selection into
		 Logic Programs",
	Booktitle = "Proceedings of the ACM 
		     Symposium on Principles of Database Systems",
	Year = 1987,
	Month = "March",
	Address = "San Diego, California",
	Pages = "214--226",
	Annote = "Considers binary chain programs.  The principle
	          result is that, associating the context free
		  grammar L(H) with every binary chain program
		  H, H is equivalent to some monadic program
		  if and only if L(H) is a regular language.
		  Note that this implies that equivalence
		  of binary chain programs to monadic programs
		  is undecidable."}

@inproceedings{bnrst:set,
	Author = "Catriel Beeri and Shamim Naqvi and Raghu
		  Ramakrishnan and Oded Shmueli and Shalom Tsur",
	Title = "Sets and Negation in a Logic Database Language",
	Booktitle = "Proceedings of the ACM 
		     Symposium on Principles of Database Systems",
	Year = 1987,
	Month = "March",
	Address = "San Diego, California",
	Pages = "21--37",
	Annote = "Discusses how to define and ensure unique minimal
		  models in a logic-based language containing
		  layered uses of sets and negation."}

@inproceedings{br:ont,
	Author = "Catriel Beeri and Raghu Ramakrishnan",
	Title = "On the Power of Magic",
	Booktitle = "Proceedings of the  ACM 
		     Symposium on Principles of Database Systems",
	Year = 1987,
	Month = "March",
	Address = "San Diego, California",
	Pages = "269--283",
	Annote = "Generalized counting and magic sets algorithms."}

@article{bv:apr,
	Author = "Catriel Beeri and Moshe Y. Vardi",
	Title = "A proof procedure for data dependencies",
	Journal = "JACM",
	Year = 1984,
	Volume = 31,
	Number = 4,
	Pages = "718-741",
	Month = "October",
	Annote = "This is a paper about the {\sl chase} procedure for
		  inferring equivalences about dependencies.  It shows
		  that for total tuple generating dependencies (those
		  which specify all attributes of the generated tuple)
		  and equality generating dependencies the problem is 
		  decidable, but for embedded dependencies the problem
		  is only semi-decidable.  (Note that this requires
		  unbounded domains.)
		  
		  The finite implication problem, do all finite relations 
		  satisfying one set of dependencies satisfy another, is
		  not even semi-decidable."}

@article{bg:pow,
	Author = "Philip A. Bernstein and Nathan Goodman",
	Title = "Power of Natural Semijoins",
	Journal = "SIAM Journal of Computing",
	Volume = 10,
	Number = 4,
	Month = "November",
	Year = 1981,
	Pages = "751--771",
	Annote = "Predecessor to Yannakakis's acyclic hypergraph
	          paper.  Shows how to use semijoins to reduce
		  communication cost in performing joins
		  in distributed relational systems."}

@article{b:tab,
	Author = "R. S. Bird",
	Title = "Tabulation Techniques for Recursive Programs",
	Journal = "Computing Surveys",
        Volume = 12,
	Number = 4,
	Month = "December",
	Pages = "403--417",
        Year = 1980,
	Annote = "This paper considers three techniques for using
		  tabulation to reduce redundancy in evaluating
		  recursive definitions.  They are
			1) Optimal Time and Space.  This approach
			   depends on the recursion and specific
			   argument, and requires a careful analysis
			   for each case.  Example: Fibonacci, with
			   only 3 storage locations.
			2) Overtabulation.  May store some results
			   that are not actually needed for a given
			   call.
			3) Exact Tabulation.  Essentially top-down
			   plus memoing."}



@techreport{bz:iss,
	Author = "Toby Bloom and Stanely B. Zdonik",
	Title = "Issues in the Design of Object-Oriented Database
		 Programming Languages",
	Institution = "Brown University",
	Number = "CS-87-19",
	Month = "July",
	Year = 1987,
	Annote = "Compares the perspectives of programming language
		  and database language designers.  Points include:
		  1) hard to minimize trigger and constraint checking
	   	  in OO language (don't know what the operators do);
		  2) hard to optimize queries for the same reason.
		  3) PL's view data as state of a process; DB's view
		  data as the main thing;  4) how can lots of data
		  be handled (they claim virtual memory is no good,
		  arguing from experience); 5) difference between
		  class as a type and class as a collection."}

@article{bb:str,
	Author = "Emde Boas, Ghica van and Emde Boas, Peter van",
	Title = "Storing and evaluating Horn-clause rules in a relational
	 	 database",
	Journal = "IBM Journal of Research and Development",
	Volume = 30,
	Number = 1,
	Month = "January",
	Year = 1986,
	Annote = "The authors describe a way of implementing logic 
		  programming using IBM Business System 12.  They map
		  structures into tuples by creating a new relation
		  for each principal functor, and storing a reference
		  to a tuple of that relation in the place of a complex
		  object.  They implement recursion by generating the
		  expansion and optimizing and evaluating each element 
		  as it is generated."}

@book{b:ran,
	Author = "B\'ela Bollob\'as",
	Title = "Random Graphs",
	Publisher = "Academic Press",
	Address = "London",
	Year = 1985}


@techreport{b:are,
	Author = "David A. Briggs",
	Title = "A Reconsideration of the Termination Conditions of
		 the {Henschen}-{Naqvi} Technique",
	Institution = "University of Massachusetts at Amherst",
	Year = 1986,
	Month = "September",
	Number = "COINS 87-11",
	Annote = "Proves that the termination condition given in the
		  Henschen-Naqvi paper for cyclic data is premature.
		  Suggests a corrections, which is indeed correct,
		  but seems to involve expensive set operations.
		  
		  Also proves that HN's initial assumptions aren't
		  enough to guarantee the simple pattern of variable
		  overlap that HN use in the expansions."}

@inproceedings{bs:inf,
	Author = "A. Brodsky and Y. Sagiv",
	Title = "Inference of Monotonicity Constraints in Datalog Programs",
	Booktitle = "Proceedings of the ACM SIGACT-SIGART-SIGMOD 
		     Symposium on Principles of Database Systems",
	Year = 1989,
	Month = "March",
	Address = "Philadelphia, Pennsylvania",
	Pages = "190-199"}

@techreport{b:que,
	Author = "Francois Bry",
	Title = "Query Evaluation in Recursive Databases: Bottom-up
                 and Top-down Reconciled",
	Year = 1989,
	Month = "April",
	Institution = "ECRC",
	Number = "IR-KB-64",
	Annote = "(Skimmed.) Presents the ``Backward Fixpoint Procedure''
                  for answering queries, and shows that Alexander
		  and Magic Sets are specializations of this procedure."}

@inproceedings{b:log,
	Author = "Francois Bry",
	Title = "Logic Programming as Constructivism: A Formalization and its 
		 Application to Databases",
	Booktitle = "Proceedings of the ACM SIGACT-SIGART-SIGMOD
		     Symposium on Principles of Database Systems",
	Year = 1989,
	Month = "March",
	Address = "Philadelphia, Pennsylvania",
	Pages = "34--50"}

@unpublished{bkv:ada,
	Author = "Adam L. Buchsbaum and Paris C. Kanellakis and
		  Jeffrey S. Vitter",
	Title = "A Data Structure for Arc Insertion and Regular
	         Path Finding",
	Month = "November",
	Year = 1988,
	Note = "Unpublished Manuscript, Brown University"}

@article{bd:atr,
	Author = "R. M. Burstall and John Darlington",
	Title = "A Transformation System for Developing
                 Recursive Programs",
	Journal = "Journal of the ACM",
	Volume = 24,
        Number = 1,
	Month = "January",
        Year = 1977,
        Pages = "44-67",
	Annote = "Gives several rewriting rules for
                  recursive (LISP-y) programs.  The
                  transformations include definition,
                  instantiation, unfolding, folding,
                  and abstraction.  Also rely on
                  ``eureka'' type insight from
                  the programmer in setting things
                  up.  Bottom-up GMS achieves the
                  same speedup as they do in Fib and
                  table-of-factorials, but can't
                  match their recursion->iteration and
                  early-exit list compares."}

@article{cw:onu,
	Author = "Luca Cardelli and Peter Wegner",
	Title = "On Understanding Types, Data Abstraction,
	         and Polymorphism",
	Journal = "Computing Surveys",
	Year = "1986",
	Volume = 17,
	Number = 4,
	Pages = "471--521",
	Annote = "Includes the statement ``object oriented =
		  data abstractions + object types + type
		  inheritance''"}

@article{cw:uni,
	Author = "J. Lawrence Carter and Mark N. Wegman",
	Title = "Universal Classes of Hash Functions",
	Journal = "Journal of Computer and System Sciences",
	Year = 1979,
	Volume = 18,
	Pages = "143--154",
	Annote = "Fill this in later."}

@inproceedings{cgw:int,
	Author = "S. Ceri and G. Gottlob and G. Wiederhold",
	Title = "Interfacing Relational Databases and Prolog
		 Efficiently",
	Booktitle = "Proceedings of the First International Conference
		     on Expert Database Systems",
	Year = 1986,
	Pages = "141--153"}

@inproceedings{ct:opt,
	Author = "S. Ceri and L. Tanca",
	Title = "Optimization of Systems of Algebraic 
	         Equations for Evaluating Datalog Queries",
	Booktitle = "Proceedings of the 13th VLDB Conference",
	Year = 1987,
	Pages = "31--41",
	Month = "September",
	Address = "Brighton, England",
	Annote = "The authors first present a method for converting
		  Datalog into algebraic equations (relational
	          algebra, except that the equations can be recursive.)
		  They then discuss how to find common subexpressions
		  in conjunctions and in unions.  This is just
		  factoring - it seems to me that sometimes you
		  might not want to factor, e.g., t :- abc,
		  s :- bc, with a selection on a variable
		  that appears in a.
		  
		  Then they present algorithms for pushing selections
		  into these equations.  The algorithms look a lot
		  like Magic Sets --- the basic idea is to replace
		  EDB with the relevant subparts of the relations.
		  However, they note that their algorithm may fail
		  to make use of some selections.
		  
		  My hunch is that their algorithm can push selections
		  when 1) the selection is on a persistent variable
		  or 2) when the selection can be pushed through
		  sideways information passing without being
		  pushed through a recursive relation."}
		  

@phdthesis{c:sem,
	Author = "U. S. Chakravarthy",
	Title = "Semantic Query Optimization in Deductive Databases",
	School = "University of Maryland",
	Year = 1985,
	Address = "College Park",
	Annote = "Haven't read it, but from the description in another
		  paper by the author it involves incorporating integrity
		  constraints in rules by subsumption, thus avoiding work
		  that the integrity constraints say is unnecessary.  I
		  think this is completely independent of naughton or
		  sagiv optimizations --- it always pays off to remove
		  redundancy, even if you're going to add integrity
		  constraints later."}

@incollection{cfm:sem,
	Author = "U. S. Chakravarthy and D. H. Fishman and J. Minker",
	Title = "Semantic Query Optimization in Expert Systems and
		 Database Systems",
	Booktitle = "Expert Database Systems",
	Publisher = "Benjamin/Cummings",
	Year = 1986,
	Editor = "L. Kerschberg",
	Pages = "659--675",
	Annote = "See entry for Chakravarthy's thesis."}

@article{ch:str,
	Author = "Ashok K. Chandra and David Harel",
	Title = "Structure and Complexity of Relational Queries",
	Journal = "Journal of Computer and System Sciences",
	Year = 1982,
	Volume = 25,
	Number = 1,
	Pages = "99-128"}

@article{ch:hor,
	Author = "Ashok K. Chandra and David Harel",
	Title = "Horn Clause Queries and Generalizations",
	Journal = "J. Logic Programming",
	Year = 1985,
	Volume = 2,
	Number = 1,
	Pages = "1--15",
	Month = "April",
	Annote = "This paper shows that Horn clause programs express
		  exactly the queries representable by a fixpoint
		  applied to a positive existential query.  This
		  implies that Horn clause programs and first order
		  expressions are incommensurate.
		  
		  In the paper they give a constructions that converts
		  mutually recursive rules into a single recursive 
		  predicate with multiple recursive rules.  The construction
	 	  adds equalities to the clauses.
		  
		  They show that adding negated ``terminal'' predicates
		  retains desirable properties of Horn clauses, and
		  can express exactly the queries representable by a
		  fixpoint applied to an existential first order
		  formula.  This still doesn't capture all of first order
		  --- in particular, it can't express universal
		  quantification."}
		  		  
@inproceedings{cm:opt,
	Author = "Ashok K. Chandra and Philip M. Merlin",
	Title = "Optimal implementation of conjunctive queries in
		relational data bases",
	Booktitle = "Conference Record of the Ninth Annual ACM
		     Symposium on Theory of Computing",
        Month = "May",
	Address = "Boulder, Colorado",
	Year = 1977,
	Pages = "77--90",
	Annote = "no note"}

@incollection{c:ont,
	Author = "C. Chang",
	Title = "On the Evaluation of Queries Containing Derived Relations
		 in a Relational Data Base",
	Booktitle = "Advances in Data Base Theory, Volume 1",
	Publisher = "Plenum Press",
	Year = 1981,
	Editor = "H. Gallaire and J. Minker and J. Nicolas"}

@incollection{cw:pro,
	Author = "C. L. Chang and A. Walker",
	Title = "{PROSQL}: A Prolog Programming Interface with {SQL/DS}",
	Booktitle = "Expert Database Systems",
	Editor = "L. Kerschberg",
	Publisher = "Benjamin/Cummings",
	Year = 1986,
	Pages = "223--246"}
	

@unpublished{ci:rec,
	Author = "Jan Chomicki and Tomasz Imielinksi",
	Title = "Recognizing pseudo-recursion in deductive databases",
	Month = "October",
	Year = 1985,
	Note = "Submitted to PODS (I think)",
	Annote = "Solves the problem for strongly typed rules of a 
		  single predicate.  Sagiv claims this is just a
		  restatement of his results from his PODS paper
		  and several ``Revenge of'' papers.  Notes that the
		  general untyped problem is much harder, not even
		  known to be decidable.
		  
		  The authors withdrew this paper after learning of
		  Sagiv's work.  Gives a sketch of a proof that can
		  be used to show that if you have to evaluate an
		  data dependent number of strings in $S$, you have to 
		  evaluate a data dependent number of predicates in
		  any evaluation strategy --- just show that in any
		  solution to finite set of first order formulas there
		  is a fixed size portion of the db that proves the
		  answer, whereas in the unbounded chains case, there
		  are answers that require arbitrarily many tuples
		  in their proof.
		  "}


@techreport{cg:par,
	Author = "Keith L. Clark and Steve Gregory",
	Title = "{PARLOG}: A Parallel Logic Programming Language",
	Institution = "Imperial College",
	Number = "Research Report DOC 83/5",
	Month = "March",
	Year = "1983",
	Annote = "Relies on programmer annotations to tell
		  which subgoals may bind which variables.
		  Only one subgoal, the ``producer,'' is
		  allowed to bind a given variable.  Got
		  this reference from DeGroot."}

@article{c:imp,
	Author = "W. F. Clocksin",
	Title = "Implementation Techniques for Prolog Databases",
	Journal = "Software---Practice and Experience",
	Volume = 15,
	Number = 7,
	Pages = "669--675",
	Month = "July",
	Year = 1985,
	Annote = "Describes how to store clauses of a prolog
	          program in a compilation-oriented system.  Key
		  points are that Prolog's applicative style
		  allows specialized garbage collection, and
		  a rather involved scheme for linking compiled
		  clauses to their source.  Nothing to do
		  with databases."}

@book{cm:pro,
	Author = "W. F. Clocksin and C. S. Mellish",
	Title = "Programming in Prolog",
	Publisher = "Springer-Verlag",
	Address = "New York, New York",
	Year = 1981,
	Annote = "Introductory Prolog text."}

@book{c:sam,
	Author = "William G. Cochran",
	Title = "Sampling Techniques",
	Publisher = "John Wiley and Sons, Inc.",	
	Address = "New York, New York",
	Edition = 3,
	Year = 1977}


	

@inproceedings{c:cae,
	Author = "Norman H. Cohen",
	Title = "Characterization and elimination of redundancy in
		 recursive programs",
	Booktitle = "Proceedings of the Sixth ACM Symposium on
		     Principles of Programming Languages",
	Year = 1979,
	Pages = "143--157",
	Annote = "Investigates when the recursive definition of a
		  function calls for redundant computation.  The
		  basic idea is that you can prove that the function
		  will be called multiple times with the same
		  arguments.  This in turn is done by looking
		  at the functions relating the initial arguments
		  to the arguments in the recursive call."}

@article{c:eli,
	Author = "Norman H. Cohen",
	Title = "Eliminating Redundant Recursive Calls",
	Journal = "ACM Transactions on Programming Languages
		   and Systems",
	Year = 1983,
	Month = "July",
	Volume = 5,
	Number = 3,
	Pages = "265--299"}

@inproceedings{cw:why,
	Author = "S.R. Cohen and O. Wolfson",
	Title = "Why a Single Parallelization Strategy is Not Enough 
		 in Knowledge Bases",
	Booktitle = "Proceedings of the ACM Symposium on 
		      Principles of Database   Systems", 
	Pages = "200--216", 
	Address = "Philadelphia, Pennsylvania", 
	Month = "March",
	Year = 1989}

@phdthesis{c:the,
	Author = "John S. Conery",
	Title = "The {AND/OR} Process Model for Parallel Execution
		 of Logic Programs",
	School = "University of California, Irvine",
	Year = 1983,
	Note = "Dept. of Information and Computer Science TR204",
	Annote = "A process-structured system that dynamically
	        monitors variables and continually develops data
		dependency networks to control the order of execution
		of subgoals, never allowing two potential producers
		for the same variable to execute in parallel.  (I
		got this from DeGroot's paper on restricted
		and-parallelism.)"}

@book{c:pra,
	Author = "W. J. Conover",
	Title = "Practical Nonparametric Statistics",
	Publisher = "John Wiley \& Sons",
	Address = "New York, New York",
	Year = 1971}


@inproceedings{cgkv:dec,
	Author = "Stavros S. Cosmadakis and Haim Gaifman and 
	          Paris Kanellakis and Moshe Y. Vardi",
	Title = "Decidable Optimization Problems for Database
	         Logic Programs",
	Booktitle = "Proceedings of the Twentieth Symposium on the Theory
		     of Computation", 
	Year = 1988,
	Address = "Chicago, Illinois",
	Month = "May",
	Pages = "477--490",
	Annote = "Main result is that boundedness is decidable
	          for monadic programs."}

@inproceedings{ck:par,
	Author = "Stavros S. Cosmadakis and Paris C. Kanellakis",
	Title = "Parallel evaluation of recursive rule queries",
	Booktitle = "Proceedings of the ACM Symposium
		     on Principles of Database Systems",
	Year = 1986,
	Month = "March",
	Address = "Cambridge, Massachusetts",
	Pages = "280--293",
	Annote = "Another result for strongly typed rules of a single
		  predicate.  (Sirrup programs) Also proves that linear 
		  recursive rules are in NC, and that there is a ``gap'' 
		  between bounded rules and rules that take log(n) time."}


@inproceedings{db:asy,
	Author = "John Darlington and R. M. Burstall",
	Title = "A System which Automatically Improves Programs",
	Booktitle = "Proceedings of the Third International Joint 
		     Conference on Artificial Intelligence",
	Location = "Stanford, California",
	Year = "1973",
	Pages = "479--485",
	Annote = "Describes their system for improving programs through
		  1) Recursion removal. 2) Eliminating Redundant
		  computations. 3) Replacing procedure calls by
		  their bodies.  4) Causing program to re-use
		  storage cells (destructive assignemnt.
	
		  Throughout their approach is one of matching
		  templates to programs.  The user is queried
		  about which transformation type he wishes
		  to attempt; then the system searches through
		  its list of transforms to try to find one
		  that applies.

		  The addition of destructive assignment is 
		  new (compared to their JACM paper.)  basically,
		  they name all storage cells, and symbolically
		  execute the program to see what can be
		  discarded where."}

@unpublished{d:som,
	Author = "Doug DeGroot",
	Title = "Some methods of and-parallel execution of logic programs",
	Month = May,
	Year = 1986,
	Annote = "A survey of and-parallelism.  ... basic techniques are
		  presented.  In the first, the programmer orders the
		  clauses and uses a ``committ'' operator to guarantee
		  the proper parallelism, based on independence, etc.
		  This is used in Concurrent Prolog (Shapiro) and
		  Parlog (Clark).
		  
		  In the second, run-time goal ordering is used to
		  try to achieve the best case.  The major problem
		  is the expense of the run-time analysis.
		  
		  In the third, a static analysis discovers the
		  worst case dependencies.  This is similar to 
		  Mellish' automatic I/O annotations.  (Suggested
		  in Chang, Despain, and Degroot.)
		  
		  Finally, in the RAP model (DeGroot), a comprimise -
		  static analysis determines what runtime tests will
		  be necessary, and uses approximate but efficient
		  testing algorithms at runtime."}
		  
		  

@inproceedings{d:res,
	Author = "Doug DeGroot",
	Title = "Restricted And-Parallelism",
	Booktitle = "Proceedings of the International Conference on Fifth 
		     Generation Computer Systems",
	Year = 1984,
	Pages = "471--478",
	Annote = "Deals with the problem of when subgoals of a clause can
		  be executed in parallel.  Notes that disjoint variables
		  isn't sufficient, nor is shared variables prohibitive.  
		  
		  The algorithm checks to see if the subgoals share variables
		  (bindings to constants through unification eliminate
		  sharing.)  The emphasis is on cheap runtime support, and
		  it may miss some opportunities. 
		  
		  Also describes a demand-driven parallel scheme.  Each
		  processor has a sequential and parallel stack of goals.
		  If a processor becomes idle, it can request a goal.  If
		  a processor receives a request, it can choose one of
		  its parallel goals to send to the requesting processor."}


@techreport{da:mov,
	Author = "Prem Devanbu and Rakesh Agrawal",
	Title = "Moving Selections into Fixpoint Queries",
	Institution = "AT\&T Bell Laboratories",
	Year = 1986,
	Annote = "Extends Aho and Ullman to include selections
		  on variables that permute through head of
		  rule.  For example, in 
		  	t(X,Y,Z) :- t(Y,X,W),e(W,Z).
			t(a,Y,Z)?
		  they would push the restriction
		  t1 = a or t2 = a into the fixpoint.  Seems
		  like you should really break it out into
		  two, i.e.
			t'(X,Y,Z) :- t'(X,Y,W),e(W,W'),e(W',Z).
			t(a,Y,Z) :- t'(a,Y,Z) or t'(Y,a,W)e(W,Z)."}


@inproceedings{dw:ext,
	Author = "Suzanne W. Dietrich and David S. Warren",
	Title = "Extension Tables: Memo relations in logic programming",
	Booktitle = "Proceedings of the Symposium on Logic Programming",
	Year = 1987,
	Pages = "264--272",
	Note = "Unpublished Manuscript",
	Annote = "Extension tables are cached partial relations for 
		  relations being evaluated.  The evaluation algorithms
		  presented using these tables maintain Prolog's
		  depth-first, left-right sematics.  They seem to be
		  more interesting as an extension of Prolog than  as
		  an evaluation algorithm for logical specifications.
		  I suspect it can be mapped to special cases of
		  bottom-up evaluation, although the author's see
		  it as more closely related to Earley Deduction."}

@article{dw:fun,	
	Author = "S.K. Debray and D.S. Warren",
	Title = "Functional compositions in logic programs",
	Journal = "Transactions on Programming Languages",
	Year =  1989,
	Annote = "Discusses sufficient conditions for inferring that a 
		  query form is functional, and various optimizations in
		  a Prolog-style evaluation for such programs. Sufficient
		  conditions similar to Reddy's."}



@inproceedings{dkmmrt:dyn,
	Author = "M. Dietzfelbinger and A. Karlin and K. Mehlhorn
		  and F. Meyer and H. Rohnert and R. E. Tarjan",
	Title = "Dynamic Perfect Hashing: Upper and Lower Bounds",
	Booktitle = "Proceedings of the 29th IEEE FOCS Conference",
	Year = 1988,
	Pages = "524--531"}

@inproceedings{d:ond,
	Author = "G. Dong",
	Title = "On Distributed Processing of Datalog Queries by 
		 Decomposing Databases",
	Booktitle = "Proceedings of the  ACM SIGMOD International Conference on
		     Management of Data",
	Pages = "26-35", 
	Address = "Portland, Oregon",
	Month = "June",
	Year= 1986}

@phdthesis{d:ont,
	Author = "Guozhu Dong",
	Title = "On the Composition and Decomposition of {DATALOG}
	         Program Mappings",
	School = "University of Southern California",
	Year = 1988,
	Month = "December",
	Note = "Considers when datalog programs can be put combined
	        or separated, presumably for reasons of efficiency."}

@article{ek:the,
	Author = "M. H. van Emden and R. A. Kowalski",
	Title = "The Semantics of Predicate Logic as a Programming Language",
	Journal = "Journal of the ACM",
	Volume = 23,
	Number = 4,
	Year = 1976,
	Pages = "733-742",
	Month = "October"}

@article{en:top,
	Author = "M. H. van Emden and M. A. Nait Abdallah",
	Title = "Top-down semantics of fair computations of logic
		 programs",
	Journal = "J. Logic Programming",
	Year = 1985,
	Volume = 2,
	Number = 1,
	Pages = "67--75",
	Month = "April",
	Annote = "Pretty heavy pounding - maybe more than it's worth.  
		  An attempt to formalize partial results of
	  	  nonterminating Prolog programs in terms of greatest
		  fixpoints of programs starting with extended
		  Herbrand models of the program and domain.
		  
		  As far as I can tell, the major result is that
		  the result of a nonterminating program is the
		  intersection of the results of all substitutions
		  that are part of some fair derivation applied
		  to the initial query."}

@article{f:hor,
	Author = "R. Fagin",
	Title = "Horn clauses and database dependencies",
	Journal = "JACM",
	Year = 1982,
	Volume = 29,
	Number = 4,
	Pages = "952--985",
	Month = "October",
	Annote = "Shows that tuple and equality generating dependencies
		  can be expressed as first-order sentences."}

@article{f:asy,
	Author = "Martin S. Feather",
	Title = "A System for Assisting Proram Transformation",
	Journal = "ACM Transactions on Programming Languages
		   and Systems",
	Volume = 4,
	Number = 1,
	Month = "January",
	Year = 1982,
	Pages = "1--20",
	Annote = "Describes an attempt to apply Burstall-Darlington
		  Program transformations to large-scale programs.
		  The negative news is that the complexity of
		  applying the rewriting seems to grow
		  non-linearly with the size of the program being
		  transformed.  His approach to dealing with this
		  is hierarchical.  The input to his system is
		  a program and a meta-program that guides the
		  transformation system in attempting to apply
		  templates to perform transformations.  Relies
	          very heavily on user guidance."}

@incollection{f:asu,
	Author = "M.S. Feather",
	Title = "A survey and classification of some program transformation
		 approaches and techniques",
	Booktitle = "Program Specification and Transformation, IFIP",
	Publisher = "Elsevier Science Publishers B.V. (North-Holland)",
	Year = 1987,
	Editor = "L.G.L.T. Meertens",
	Pages = "165--195",
	Annote = "Seems more a survey of projects in the area."}


@book{f:ani,
	Author = "William Feller",
	Title = "An Introduction to Probability Theory and Its
	         Applications",
	Volume = 1,
	Publisher = "John Wiley and Sons, Inc.",
	Address = "New York, New York",
	Year = 1968}

@article{fm:pro,
	Author = "P. Flajolet and G. N. Martin",
	Title = "Probabilistic Counting Algorithms for Data Base Applications",
	Journal = "JCSS",
	Volume = 31,
	Year = 1985}

@inproceedings{gmsv:und,
	Author = "Haim Gaifman and Harry Mairson and Yehoshua Sagiv and
		  Moshe Y. Vardi",
	Title = "Undecidable Optimization Problems for Database Logic
		 Programs",
	Booktitle = "Proceedings of the Second IEEE Symposium on 
		     Logic in Computer Science",
	Year = 1987,
	Month = "June",
	Pages = "106--115",
	Address = "Ithaca, New York",
	Annote = "Includes the proof that boundedness is undecidable.
	          Generalizes the proof to show that any property that
		  is 1) Strongly semantic (if P1 <=> P2, then both
		  have the property or both don't) and 2) nontrivial
		  (exist programs that do and don't have it) and
		  3) contains boundedness is
		  undecidable."}

@article{gmn:log,
	Author = "Herve Gallaire and Jack Minker and Jean M. Nicolas",
	Title = "Logic and Databases: A Deductive Approach",
	Journal = "Computing Surveys",
	Year = 1984,
	Volume = 16,
	Pages = "153--185"}

@inproceedings{gks:ana,
	Author = "S. Ganguly and R. Krishnamurthy and A. Silberschatz",
	Title = "An Analysis Technique for Transitive Closure Algorithms:\
		 A Statistical Approach",
	Booktitle = "Proceedings of the IEEE Data Engineering Conference",
	Year = "1991",
	Note = "To appear"}

@inproceedings{gst:afr,
	Author = "S. Ganguly and A. Silberschatz and S. Tsur",
	Title =  "A Framework for the Parallel Processing of Datalog Queries",
	Booktitle = "Proceedings of the ACM SIGMOD International Conference
		   on Management of Data",
	Address = "Atlantic City, New Jersey",
	Month =  "May",
	Year = "1990",
	Note = "To appear."}

@inproceedings{gd:eva,
	Author = "G. Gardarin and C. DeMaindreville",
	Title = "Evaluation of Database Recursive Logic Programs as
		 Recursive Function Series",
	Booktitle = "Proceedings of the ACM SIGMOD International Conference
		     on Management of Data",
	Address = "Washington, D.C.",
	Month = "May",
	Year = 1986}

@article{gg:ont,
	Author = "Erol Gelenbe and Daniele Gardy",
	Title = "On the sizes of projections: I",
	Journal = "Information Processing Letters",
	Volume = 14,
	Number = 1,
	Year = 1982,
	Month = "March",
	Pages = "18--21",
	Annote = "Assumes uniform distribution of elements from known
                  domain size for each column of a relation, then 
                  computes the probabilities for various sizes of
                  various projections.

                  Some problems:  1) assumption of uniformity and
                  independence of attributes.  2) requires knowing
                  the size of domains.  What if elements are chosen
                  from a very large domain, e.g., SS numbers?  3) Computes
                  probability projection is of size x, for given x.
                  It's unclear how to find the x of maximal probability.
                  4) requires order $n^3$ operations, which is infeasible
                  even for n = 10000."}

@inproceedings{gg:ont2,
	Author = "Erol Gelenbe and Daniele Gardy",
	Title = "On the sizes of projections: {II}",
	Booktitle = "Proceedings of the 8th VLDB Conference",
	Address = "Mexico City, Mexico", 
	Year = "1982",
	Month = "September",
	Annote = "Extends part I by assuming FDs and also computing
                  the expected value of the size (instead of just the
                  probabilities of each size."}

@techreport{g:mrs,
	Author = "Michael R. Genesereth",
	Title = "MRS: A Metalevel Representation System",
	Institution = "Stanford University",
	Number = "HPP-83-28",
	Year = 1983,
	Annote = "No note"}

@techreport{g:the,
	Author = "Michael R. Genesereth",
	Title = "The {MRS} Casebook",
	Institution = "Stanford University",
	Month = "May",
	Year = 1983,
	Number = "HPP-83-26"}

@inproceedings{gss:eff,
	Author = "Gosta Grahne and Seppo Sippu and Eljas
		  Soisalon-Soininen",
	Title = "Efficient Evaluation for a Subset of Recursive Queries",
	Booktitle = "Proceedings of the ACM 
		     Symposium on Principles of Database Systems",
	Year = 1987,
	Month = "March",
	Address = "San Diego, California",
	Pages = "284--293",
	Annote = "The authors describe an algorithm for evaluating
		  selections on linear recursive rules that contain
		  binary relations.  There is also some material 
		  about converting definitions with non-binary
		  relations to equivalent definitions with
		  binary relations.
		  
		  The algorithm seems very close to Henschen and
		  Naqvi's, although I don't understand it well
		  enough to be sure.  On the t :- atb recursions,
		  they state a time bound of (the number of tuples
		  in a in some path of form aicbi plus the number
		  of tuples in b in some path of the form aicbi)
		  times (the number of tuples in a plus the number
		  of tuples in b).  Here one time unit seems to be
		  one tuple use."}

@inproceedings{hn:couconf,
	Author = "Ramsey W. Haddad and Jeffrey F. Naughton",
	Title = "Counting Methods for Cyclic Relations",
	Booktitle = "Proceedings of the ACM 
	             Symposium on Principles of Database Systems",
	Year = 1988,
	Month = "March",
	Address = "Austin, Texas",
	Pages = "333-340"}

@article{hn:cou,
	Author = "Ramsey W. Haddad and Jeffrey F. Naughton",
	Title = "Counting Methods for Cyclic Relations",
	Journal = "Journal of Computer and System Sciences",
	Volume = 43,
	Number = 1,
	Month = "August",
	Year = 1991,
	Pages = "145--169"}

@inproceedings{h:ser,
	Author = "Thanasis Hadzilacos",
	Title = "Serialization Graph Algorithms for Multiversion
                 Concurrency Control",
	Booktitle = "Proceedings of the ACM SIGACT-SIGART-SIGMOD
                     Symposium on Principles of Database Systems",
	Year = 1988,
	Month = "March",
	Pages = "135--141",
	Annote = "(from the abstract) We propose a new algorithmic framework
                  which generalizes all concurrency control methods known
                  so far.  This class of algorithms...works by
                  monitoring the acyclicity of the serialization
                  graph."}

@inproceedings{hl:proc,
	Author = "J. Han and L. Liu",
	Title = "Processing multiple linear recursions",
	Booktitle = "Proceedings of the North American
	Conference on Logic Programming",
	Year = 1989,
	Address = "Cleveland, Ohio",
	Month = "October",
	Annote = "Elaborates on the idea of taking some unions
		  before iterating; sometimes a win. Discusses
		  how Magic Sets can be modified using this idea."}



@inproceedings{hh:han,
	Author = "Jiawei Han and Lawrence J. Henschen",
	Title = "Handling Redundancy in the Processing of Recursive Database
		 Queries",
	Booktitle = "Proceedings of the ACM-SIGMOD Conference on the
		     Management of Data",
	Pages = "73--81",
	Year = 1987,
	Month = "May",
	Address = "San Fransisco, California",
	Annote = "The authors identify 4 levels of redundancy: 
	          precompilation (redundant predicates and rules),
		  iteration level (reusing results of previous iterations),
		  tuple level (``cyclic'' or ``asynchronous'' data),
		  and file level.
		  
		  They assume chain or almost chain rules."}

@phdthesis{h:thesis,
	Author = "Jiawei Han",
	Title = "",
	School = "University of Wisconsin, Madison",
	Year = 1987}

@techreport{hh:pro,
	Author = "Jiawei Han and Lawrence J.~Henschen",
	Title = "Processing Linear Recursive Database Queries
		 by Level and Cycle Merging",
	Institution = "Northwestern University",
	Year = 1987,
	Number = "EE/CS TR 87-05-DBM-01",
	Annote = "The authors present several algorithms for
	          evaluating selections on t :- atb.  Each
		  algorithm is appropriate for different kinds
		  of data - synchronous (each node in a reachable
		  from the query node at only one level), 
		  asynchroous but acyclic, and cyclic.  The 
		  interesting stuff is in the cyclic algorithm.

                  Their algorithm requires that you find all simple
		  cycles in the database.  There can be a lot, so they 
		  observes that the simple cycles are independent of the 
		  query, so that phase of the algorithm need only be done 
		  once each time the data is changed.

		  The simple cycles are used to find the ``Self 
		  Level-Cycle List'' of each node.  A level-cycle element 
		  is something of the form l(c1,c2,...,cn) and has the 
		  meaning that there are paths from p to p of length 
		  l + k1c1 + k2c2 + ... + kncn, ki > 0.  A level-cycle 
		  list is a list of level-cycle elements.  

		  A level-cycle element can be exponential in size, but 
		  here's where the paper starts getting a little hard to 
		  evaluate.  The authors give 8 heuristics to simplify one 
		  of these lists, and claim that for ``real'' databases 
		  these simplifications succeed in reducing level-cycle lists
		  to lists of a few, small level-cycle elements.  

	          Once the self level-cycle list for each element has 
		  been determined and stored, the query processing begins.  
		  It involves determining the level-cycle list for every 
		  element in A reachable from the query constant.  Again, 
		  this requires merging bunches of level-cycle lists,
		  which will square the length of each list at each merge 
		  unless the simplification heuristics help out.  Perhaps 
		  worse, suppose that (p,q) appears in A.  Then when that 
		  edge is traversed, in addition to merging the 
		  level-cycle lists of p and q the level-cycle lists of all
		  successors of q are updated.  This certainly seems like an 
		  n^2 process, where n is the number of nodes in A reachable 
		  from p.  Note that the query can be solved using the 
		  naive counting method + a counter that stops the 
		  algorithm after n^2 steps."}


@inproceedings{hl:som,
	Author = "Jiawei Han and Hongjun Lu",
	Title = "Some Performance Results on  Recursive Query Processing
		 in Relational Database Systems",
	Booktitle = "Proceedings of the International Conference on Data
		     Engineering",
	Year = 1986,
	Pages = "533--541",
	Annote = "The authors present analytic models and experimental
		  data for simulating 3 algorithms on t :- p,t,q, with
		  a selection on t.  The three algorithms are Henschen
		  and Naqvi, Bottom-up, and ``Double wavefront'', which
		  is HN on the p predicates, bottom-up on the q, with
		  a join of the two.
		  
		  The conclusions aren't too surprising --- things vary
		  a lot on the selectivity and join selectivity.  HN does
		  pretty well as long as the selectivity on p is low 
		  (a small part of p is selected for.)"}

@article{h:rev,
	Author = "David Harel",
	Title = "Review of ``Logic and Databases'' by Gallaire and
		 Minker",
	Month = "August",
	Journal = "Computer Reviews",
	Voume = 21,
	Number = 8,
	Pages = "367--369",
	Annote = "Very critical review (``neither good logic nor
		  good databases.'')  Among the objections: data
		  is given, not computed; the languages aren't
		  first order, although they are claimed to be."}

@unpublished{h:log,
	Author = "David Harel",
	Title = "Logic and Databases: A Critique",
	Year = 1986,
	Institution = "The Weizmann Institute of Science",
	Annote = "I think this appeared in a SIGACT newletter
		  sometime.  This is Harel's critique of GMN's
		  survey paper in Computer Surveys.  Again he
		  objects to calling logic-based query languages
		  ``first-order.''  He thinks that fundamental
		  research issues are being glossed over - 
		  including the tradeoffs between implicit
		  and explicit data.  In general he says the
		  approach is too language oriented and not
		  enough issue oriented."}
		  

@article{hm:enh,
	Author = "David J. Hartzband and Fred J. Maryanski",
	Title = "Enhancing Knowledge Representation in Engineering
		 Databases",
	Journal = "IEEE Computer",
	Year = 1985,
	Month = "September",
	Volume = 18,
	Number = 9,
	Pages = "39--48",
	Annote = "A survey paper, useful mainly for its bibliography.
		  They say engineering data needs improvements on 
		  the relational model because it needs a wide range
		  of data types, the ability to express complex 
		  relationships among elements of the model, and
		  the representation of knowledge (about the data?)."}
		  
@inproceedings{hdor:ano,
	Author = "Sandra Heiler and Umeshwar Dayal and Jack Orenstein
		  and Susan Radke-Sproull",
	Title = "An Object-Oriented Approach to Data Management:
		 Why Design Databases Need It",
	Booktitle = "Proceedings of the 24th ACM/IEEE Design
		     Automation Conference",
	Year = 1987,
	Pages = "335--340",
	Annote = "Sort of a position paper on why we should use
		  object-oriented databases in design applications.
		  The principle argument seems to be that the
		  engineer's model is in terms of objects and
		  operations, and using an object-oriented user
		  interface makes it easier for the engineer to
		  interact with the system, and implementing
		  the object-oriented interface will be easier
		  in an object-oriented system.
		  
		  The extensions to smalltalk needed include
		  persistent objects, operations as first
		  class objects (so the operations themselves
		  can be managed,) concurrency control and
		  crash recovery, arbitrary relationships and
		  views.  (More views than just abstraction/
		  implementation."}

@inproceedings{h:ind,
	Author = "Richard Helm",
	Title = "Inductive and Deductive Control
                 of Logic Programs",
	Booktitle = "Proceedings of the International Conference
                     on Logic Programming",
	Year = 1987,
	Pages = "488--511",
	Address = "Melbourne, Australia",
	Annote = "This paper advocates controlling the execution
                  of logic programs through control expressions,
		  in a language much like regular expressions.
		  Among the claimed benefits are avoidance of
                  redundant, failed, and infinite derivation
                  paths, and programming through under
                  specification plus control."}
	

@techreport{h:det,
	Author = "A. Richard Helm",
	Title = "Detecting and Eliminating Redundant Derivations
                 in Deductive Database Systems",
	Institution = "IBM Thomas Watson Research Center",
	Month = "December",
	Year = 1988,
        Number = "RC 14244 (\#63767)",
	Annote = "This paper seeks to eliminate redundant
                  derivations through rewriting.  An example
                  of a redundant derivation is applying the
                  rule $p(X,Y) :- p(Y,X)$ three times.  The
                  transformation can explode the number of
                  rules and predicates."}

		  
@article{hn:onc,
	Author = "Lawrence J. Henschen and Shamim A. Naqvi",
	Title = "On compiling queries in recursive first order databases",
	Journal = "Journal of the ACM",
	Year = 1984,
	Volume = 31,
	Number = 1,
	Pages = "47--85",
	Annote = "Proposes a method that seems to work well for linear
		  rules.  Takes advantage of bindings and shared variables
		  in chains to restrict lookups.  Allows lots of redundancy
		  in the chains, and leaves control of multiple rules to
		  Operating System researchers."}

@article{h:eli,
	Author = "J. Hilden",
	Title = "Elimination of Recursive Calls Using a Small Table of
		 ``Randomly'' Selected Function Values",
	Journal = "Nordisk Tidsckrift For Informationsbehandling (BIT)",
	Volume = 16,
	Number = 1,
	Year = 1976,
	Pages = "60--73",
	Annote = "Discusses techniques for managing a cache of function
		  values to reduce number of recursive calls.  Most interesting
		  thing is probably the example program he gives:
	          a(S,N,M,0) :- S < N(N+1)/2.
		  a(S,N,M,0) :- S > N(N+1)/2+NM.
		  a(S,N,M,1) :- S = N(N+1)/2.
		  a(S,N,M,1) :- S = N(N+1)/2 + NM.
		  a(S,N,M,X1+X2) :- a(S-N-M,N-1,M,X1),a(S,N,M-1,X2).
		  This arises in the computation of the Wilcox rank sum
		  in distribution-free statistics."}

@article{h:der,
	Author = "C. J. Hogger",
	Title = "Derivation of Logic Programs",
	Journal = "Journal of the ACM",
	Volume = 23,
	Number = 4,
	Year = 1976,
	Annote = "not read."}

@inproceedings{hot:sta,
	Author = "Wen-Chi Hou and Gultekin Ozsoyoglu and Baldeao K. Taneja",
	Title = "Statistical Estimators for Relational Algebra Expressions",
	Booktitle = "Proceedings of the Seventh ACM Symposium on Principles
		     of Database Systems",
	Year = 1988,
	Month = "March",
	Address = "Austin, Texas",
	Pages = "276--287",
	Annote = "The authors discuss how to estimate the number of
		  tuples satisfying a relational operation by using
		  sampling.  They model the answer to a query
		  containing $k$ relations as a set of points
		  in a $k$ dimensional space, set to 1 if the
		  tuples in the $k$ relations combine under the
		  operation to produce an answer.  This works
		  for operations such as join, selection, and
		  union, but fails for project and intersect,
		  because you can't tell whether a point in the
		  space is a 0 or a 1 just by looking at the
		  $k$ tuples specifying the point.  More sophisticated
		  algorithmms are given for such operations.

		  A lot of the paper concentrates on converting
		  queries to an appropriate normal form, and how
		  to combine estimates as you go up the query
	          tree in that standard form.

		  I couldn't find any clean results about the 
		  confidence or accuracy of the estimates."}

@inproceedings{hot:pro,
	Author = "Wen-Chi Hou and Gultekin Ozsoyoglu and Baldeao K. Taneja",
	Title = "Processing Aggregate Relational Queries with Hard Time 
                 Constraints",
	Booktitle = "Proceedings of the ACM-SIGMOD Conference on the
                     Management of Data",
	Year = 1989,
	Month = "June",
	Address = "Portland, Oregon",
	Pages = "68--77",
	Annote = "Considers how to give an estimate within a time
                  bound by sampling until the deadline hits.  Some
                  care must be taken to ensure that the current
                  sample doesn't overuse its time bound."}


@book{hu:int,
	Author = "John E. Hopcroft and Jeffrey D. Ullman",
	Title = "Introduction to Automata Theory, Languages, and
		Computation",
	Publisher = "Addison-Wesley Publishing Company",
	Address = "Reading, MA",
	Year = 1979}.

@article{ht:gen,
	Author = "Susan Horwitz and Tim Teitelbaum",
	Title = "Generating Editing Environments Based on
		 Relations and Attributes",
	Journal = "ACM Transactions on Programming Languages and
		   Systems",
	Year = 1986,
	Volume = 8,
	Number = 4,
	Month = "October",
	Pages = "577--608",
	Annote = "Another approach to smart editors for program
   		  development.  Programs are represented as
		  attributed abstract-syntax trees with an
		  associated relational database.  Claims advantages
		  over pure relational system: efficiency.  Over
		  pure attribute grammar approach: ease of
		  communicating non-local information.  Also 
		  contains stuff about efficient incremental
		  updating, and ``virtual relations'' that are
		  defined by syntax tree traversal rather than
		  tuples in the system."}

@article{h:ali,
	Author = "D. S. Hirschberg",
	Title = "A linear space algorithm for computing maximal
                 common subsequences",
	Journal = "Communications of the ACM",
	Volume = 18,
	Number = 6,
	Month = "June",
	Year = 1975,
	Pages = "341--343"}

@article{hl:pro,
	Author = "Gerard Huet and Bernard Lang",
	Title = "Proving and Applying Program Transformations
                 Expressed with Second-Order Patterns",
	Journal = "Acta Informatica",
	Volume = 11,
	Year = 1978,
  	Pages = "31-55",
	Annote = "A step toward formalizing program transformations.
                  Focusses on ``recursion removal.''  The basic
 		  idea is to match a second order template describing
 		  a transformation.  The transformation itself is
		  proven correct using denotational semantics."}

@article{i:bou,
	Author = "Yannis E. Ioannidis",
	Title = "Bounded recursion in deductive data\-bases",
	Journal = "Algorithmica",
	Month = "October",
	Year = 1986,
        Volume = 1,
	Number = 4,
	Pages = "361--385"}

@inproceedings{i:ati,
	Author = "Yannis E. Ioannidis",
	Title = "A time bound on the materialization of some recursively
		 defined views",
	Year = 1985,
	Booktitle = "Proceedings of the 11th International VLDB Conference",
	Address = "Stockholm, Sweden",
	Month = "August",
	Pages = "219--226"}

@inproceedings{i:com,
	Author = "Yannis E. Ioannidis",
	Title = "Commutativity and its Role in the Processing of
		 Linear Recursion",
	Booktitle = "Proceedings of the Fifteenth International 
		     Conference on Very Large Databases",
	Pages = "155--163",
	Month = "August",
	Year = "1989",
	Address = "Amsterdam, The Netherlands",
	Annote = "Shows how commutativity explains redundant
                  predicates and separable recursions."}  
	

@inproceedings{iw:tra,
	Author = "Yannis E. Ioannidis and Eugene Wong",
	Title = "Transforming Nonlinear Recursion into 
	         Linear Recursion",
	Booktitle = "Proceedings of the International Conference
	             on Expert Database Systems",
	Year = 1988,
	Pages = "187--207",
	Annote = "Gives an algebraic formulation for mutual recursions.
	          Also proves that every recursion is equivalent to
		  some bilinear recursion, and gives a simple 
		  condition to guarantee equivalence to a linear
		  recursion (power-subassociativity.) An important
		  problem left open seems to be how
		  to apply this stuff, e.g., how can you tell from a recursion
		  if it's power-subassociative?"}

@inproceedings{iw:que,
	Author = "Yannis E. Ioannidis and Eugene Wong",
	Title = "Query Optimization by Simulated Annealing",
	Booktitle = "Proceedings of the ACM-SIGMOD Conference
		     on the Management of Data",
        Year = 1987,
	Month = "May",
	Address = "San Fransisco, California",
	Pages = "9--22",
	Annote = "The main point is that exhaustive search is no longer
		  practical with recursion/deductive databases, because
		  the number of possible execution strategies is so big.
		  
		  Simulated annealing works by doing local transformations,
		  controlled by the ``temperature'' which decides how big an
		  increase in cost function is tolerated and decreases
		  to zero throughout the execution.
		  
		  They assume the number of iterations before convergence
		  is known, and consider tranformations on the elements of 
		  the first n iterations.  The transformations considered
		  include distributing joins over unions, associativity
		  of joins and unions, and commutativity of unions.
		  
		  Questions raised: needs a good cost function if at all
		  useful, and as yet there really is none.  I'm unsure
		  if enough strategies can be represented as transformations
		  of some initial strategy."}

@techreport{iw:tow,
	Author = "Yannis E. Ioannidis and Eugene Wong",
	Title = "Towards an Algebraic Theory of Recursion",
	Institution = "Computer Sciences Department, University
                       of Wisconsin-Madison",
	Number = "801",
	Month = "October",
	Year = "1988",
	Annote = "Just what the title says --- a framework for
                  viewing recursions in deductive databases
                  as operators in algebraic systems."}  

@article{i:amo,
	Author = "G. F. Italiano",
	Title = "Amoritized efficiency of a path retrieval data
	         structure",
	Journal = "Theoretical Computer Science",
	Year = 1986,
	Number = 48,
	Pages = "273--281"}


@inproceedings{ajn:ast,
	Author = "H. V. Jagadish and Rakesh Agrawal and  Linda Ness",
	Title = "A Study of Transitive Closure as a Recursion
		 Mechanism",
	Booktitle = "Proceedings of the ACM-SIGMOD International
		     Conference on Management of Data",
	Year = 1987,
	Address = "San Fransisco, California",
	Month = "May",
	Annote = "Check the title and pages on this one.
		  Notices that if you are willing to take cross
		  products and ignore selection constants then
		  you can express any linear recursion as a
		  transitive closure."}

@inproceedings{j:lin,
	Author = "H. V. Jagadish",
	Title = "Linear Clustering of Objects with Multiple Attributes",
	Booktitle = "Proceedings of the ACM-SIGMOD International
                     Conference on Management of Data",
	Year = 1990,
	Address = "Atlantic City, New Jersey",
	Month = "May",
	Pages = "332--342",
	Annote = "The problem considered here is how to map multidimensional
                  spaces into one dimensional spaces in such a way that
                  related objects are close.  That is, if you scan along
                  one dimension, you'd like to get consecutive runs
                  in the single dimension; if you select a region, you'd
                  like everything in the region to be close together.
                  The conclusion seems to be that gray-code or Hilbert curve
                  based approaches perform about the same and are somewhat
                  better than Z-curve and much better than row- or 
                  column-major ordering."}

@inproceedings{jcv:ano,
	Author = "Matthias Jarke, Jim Clifford, Yannis Vassiliou",
	Title = "An Optimizing Prolog Front-End to a Relational Query
		 System",
	Booktitle = "Proceedings of the SIGACT-SIGMOD Conference",
	Year = 1984,
	Pages = "296--306",
	Address = "Boston, Massachusetts",
	Month = "June",
	Annote = "The authors describe a system that is basically 
		  Prolog on top of SQL, with an intermediate language,
		  DBCL, in between.  DBCL looks like tableaux; the
		  optimizations seem to be mainly tableau minimization,
		  and grouping of Prolog's tuple at a time requests to
		  provide set at a time queries to SQL.  They say there
		  is a lot more work needed on recursive queries.  The
		  bibliography contains a lot of (at least to me) obscure
		  DB stuff."}

@incollection{k:logcomp,
	Author = "Paris C. Kanellakis",
	Title = "Logic Programs and Parallel Complexity",
	Booktitle = "Foundations of Deductive Databases and Logic
		     Programming",
	Editor = "Jack Minker",
	Publisher = "Morgan Kaufmann",
	Address = "Los Altos, California, 94022",
	Pages = "547--585",
	Year = "1988",
	Annote = "No note."}


@inproceedings{ku:par,
	Author = "Anna Karlin and Eli Upfal",
	Title = "Parallel hashing --- an efficient
	         implementation of shared memory",
	Booktitle = "Proceedings of the 27th Annual
	             Symposium on Computer Science",
	Year = 1986}

@article{k:thetransitive,
	Author = "Richard M. Karp",
	Title = "The Transitive Closure of a Random Digraph",
	Journal = "Random Structures and Algorithms",
	Volume = 1,
	Number = 1,
	Year = 1990,
	Pages = "73--93"}
	


@inproceedings{kl:mon,
	Author = "Richard M. Karp and Michael Luby",
	Title = "{Monte-Carlo} Algorithms for Enumeration and Reliability
		 Problems",
	Booktitle = "Proceedings of the IEEE Symposium on the Theory of
		     Computation",
	Year = 1983,
	Pages = "56--64"}

@unpublished{kr:asu,
	Author = "Richard M. Karp and Vijaya Ramachandran",
	Title = "A Survey of Parallel Algorithms for Shared-Memory
	         Machines",
	Year = 1988,
	Note = "Unpublished Manuscript, University of California, Berkeley"}

@article{ks:app,
	Author = "Robert M. Keller and M. Ronan Sleep",
	Title = "Applicative Caching",
	Journal = "ACM Transactions on Programming Languages and Systems",
	Year = 1986,
	Volume = 8,
	Number = 1,
	Pages = "88--108",
	Annote = "Another paper about caching results of functions to avoid
		  recomputation.  The paper spends a lot of time on
		  constructs to try to remain faithful to the functional
		  programming model.  The ``caching'' is under programmer
		  control."}

@inproceedings{kot:opt,
	Author = "Charles Kellogg and Anthony O'Hare and Larry Travis",
	Title = "Optimizing the Rule-Data Interface in a {KMS}",
	Booktitle = "Proceedings of the Twelfth International Conference
		     on Very Large Databases",
	Month = "August",
	Year = 1986,
	Pages = "42--51",
	Annote = "Considers recursion-free horn clause programs.  Major
		  point is that structure sharing to eliminate 
		  duplication is critical."}


@book{k:exp,
	Author = "L. Kerschberg",
	Title = "Expert Database Systems",
	Publisher = "Benjamin/Cummings",
	Year = 1986}


@inproceedings{kl:afr,
	Author = "Michael Kifer and Eliezer L. Lozinskii",
	Title = "A Framework for an Efficient Implementation of
		 Deductive Databases",
	Booktitle = "Proceedings of the Advanced Database Symposium",
	Year = 1986,
	Address = "Tokyo, Japan",
	Annote = "Another dynamic method for recursive query evaluation.
		  Uses static and dynamic filtering.  The key point
		  seems to be 1) constructing a system graph for
		  program and query 2) evaluating it.  This involves
		  explicitly constructing parent/child relationships
		  among goals and rules."}

@article{kl:syg,
	Author = "Michael Kifer and Eliezer L. Lozinskii",
	Title = "{SYGRAF}: Implementing Logic Programs in a 
                 Database Style",
	Journal = "IEEE Transactions on Software Engineering",
	Year = 1988,
	Annote = "Essentially kl:afr except that it extends things
		  to handle function symbols and nonground tuples."}

@book{k:sem,
	Author = "Donald E. Knuth",
	Title = "The Art of Computer Programming Volume {II}: 
		 Seminumerical Algorithms",
	Publisher = "Addison-Wesley",
	Address = "Reading, Massachusetts",
	Year = 1981}
	

@book{k:log,
	Author = "Robert A. Kowalski",
	Title = "Logic for Problem Solving",
	Publisher = "North Holland",
	Address = "New York, New York",
	Year = 1980,
	Annote = "Intro to logic programming text."}

@inproceedings{kbz:opt,
	Author = "Ravi Krishnamurthy and Haran Boral and Carlo Zaniolo",
	Title = "Optimization of Nonrecursive Queries",
	Booktitle = "Proceedings of the Twelfth VLDB Conference",
	Year = 1986,
	Pages = "128--137",
	Address = "Kyoto, Japan",
	Month = "August",
	Annote = "Gives an $n^2$ algorithm for discovering
	          an optimal linear order if the join is
		  acyclic."}

@inproceedings{krs:afr,
	Author = "Ravi Krishnamurthy and Raghu Ramakrishnan and 
	          Oded Shmueli",
	Title = "A Framework for Testing Safety and Effective
		 Computability of Extended Datalog",
	Booktitle = "Proceedings of the ACM SIGMOD International
	             Conference on Management of Data",
	Year = 1988,
	Pages = "154--163",
	Address = "Chicago, Illinois",
	Month = "May",
	Annote = "Also have full version in TR.  This paper gives
	          a methodology for testing for safety in general
		  logic programs.  The method works by first
		  rewriting to replace function symbols by
		  infinite base relations, then walking over
		  the result, testing for safety.  Here ``safety''
		  is with respect to bottom-up computation."}

@inproceedings{kz:saf,
	Author = "Ravi Krishnamurthy and Carlo Zaniolo",
	Title = "Safety and Optimization of Horn Clause Queries",
	Booktitle = "Proceedings of the XP 7.52 Workshop on Database Theory",
	Year = 1986}


@techreport{ky:pro,
	Author = "S. Kunifuji and H. Yokuta",
	Title = "{PROLOG} and relational databases for fifth-generation
		 computer systems",
	Institution = "ICOT",
	Number = "TR002",
	Year = 1982,
	Annote = "No note"}

@inproceedings{k:logs,
	Author = "Gabriel M. Kuper",
	Title = "Logic programming with sets",
	Booktitle = "Proceedings of the ACM 
		     Symposium on Principles of Database Systems",
	Year = 1987,
	Month = "March",
	Address = "San Diego, California",
	Annote = "Extends Horn Clauses to allow set variables and
		  rules of the form 
		  	A :- (x1 in X1, ..., xn in Xn)(B1 and ... Bm)
		  The purpose is to provide a query language that deals
		  well with aggregation, since sets as lists can be 
		  awkward.  He repeats the Model and Proof theoretic
		  treatments of first order logic.  The primary
		  additions are two types of variables, and interpreted
		  member and set equality axioms.  Leaves lots of
		  questions open about implementability."}


@techreport{l:que,
	Author = "Mark A. Linton",
	Title = "Queries and Views of Programs Using a Relational
	         Database System",
	Institution = "University of California at Berkeley",
	Year = 1983,
	Month = "December",
	Number = "UCB/CSD 83/164"}


@techreport{l:fab,
	Author = "Mark A. Linton",
	Title = "{FABRIC}: A Package for Managing Interwoven Data",
	Institution = "Stanford Computer Systems Laboratory",
	Year = 1985,
	Month = "March",
	Number = "85-268",
	Annote = "FABRIC is a package for managing both relational
		  and recursively defined data structures.  It is
		  a collection of Modula2 packages.  A major motivation
		  seems to have been databases for views of programs.
		  
		  It allows non-procedural constructs, providing
		  tuple references to allow structure in the
		  data.  It provides facilities for recursively
		  defined structures to be clustered for efficient
		  disk access."}

@unpublished{ln:clo,
	Author = "Richard J. Lipton and Jeffrey F. Naughton",
	Title = "Clocked Adversaries for Hashing",
	Institution = "Princeton University",
	Year = 1989,
	Note = "Submitted for publication."}

@inproceedings{ln:est,
	Author = "Richard J. Lipton and Jeffrey F. Naughton",
	Title = "Estimating the Size of Generalized Transitive Closures",
	Booktitle = "Proceedings of the Fifteenth International
		     Conference on Very Large Databases",
	Month = "August",
	Year = 1989,
	Address = "Amsterdam, The Netherlands",
	Pages = "165--172"}

@inproceedings{ln:que,
	Author = "Richard J. Lipton and Jeffrey F. Naughton",
	Title = "Query Size Estimation by Adaptive Sampling",
	Booktitle = "Proceedings of the ACM SIGACT-SIGMOD-SIGART
                     Symposium on Principles of Database Systems",
	Address = "Nashville, Tennessee",
	Year = 1990,
	Month = "March"}

@inproceedings{lns:pra,
	Author = "Richard A. Lipton and Jeffrey F. Naughton and Donovan A.
		  Schneider",
	Title = "Practical Selectivity Estimation through Adaptive Sampling",
	Booktitle = "Proceedings of the ACM SIGMOD International Conference
                     on Management of Data",
	Year = 1990,
	Month = "May",
	Address = "Atlantic City, New Jersey"}

@book{l:fou,
	Author = "John W. Lloyd",
	Title = "Foundations of Logic Programming",
	Publisher = "Springer-Verlag",
	Year = 1984}


@inproceedings{l:eva,
	Author = "Eliezer L. Lozinskii",
	Title = "Evaluating Queries in Deductive Databases by Generating",
	Booktitle = "Proceedings of the 11th International Joint
		     Conference on Artificial Intelligence",
	Year = 1985}

@inproceedings{lmr:des,
	Author = "Hongjun Lu and Krishna Mikkilineni and James P.
	         Richardson",
	Title = "Design and Evaluation of Algorithms to Compute
	         the Transitive Closure of a Database Relation",
	Booktitle = "Proceedings of the Third International
	             Conference on Data Engineering",
	Year = 1987,
	Pages = "112--119",
	Annote = "Focusses on Warren's algorithm,
		  tries to reduce block accesses."}

@inproceedings{m:equ,
	Author = "Michael J. Maher",
	Title = "Equivalences of logic programs",
	Booktitle = "Foundations of Deductive Databases 
		     and Logic Programming",
	Editor = "Jack Minker",
	Publisher = "Morgan Kaufmann Publishers, Inc.",
	Address = "Los Altos, California, 94022",
	Year = "1988",
	Pages = "627--658"}

@phdthesis{m:sem,
	Author = "Michael J. Maher",
	Title = "Semantics of Logic Programs",
	School = "Department of Computer Science, University of Melbourne",
	Year = 1985,
	Address = "Melbourne, Australia",
	Annote = "Denotational semantics, chaotic iterations, various
		  notions of equivalences, sufficient conditions for
		  commutativity and decomposability, etc."}

@inproceedings{m:atr,
	Author = "M.J. Maher",
	Title = "A Transformation System for Deductive Database
		 Modules with Perfect Model Semantics",
	Booktitle = "Proceedings of the Conference on Foundations of Software 
		     Technology and Theoretical Computer Science",
	Year = 1989,
	Address = "Bangalore, India",
	Month = "December",
	Annote = "Presents a transformation system with fold/unfold etc.,
		  and shows that it preserves the Clark completion semantics."}





@inproceedings{mr:dej,
	Author = "Michael J. Maher and Raghu Ramakrishnan",
	Title = "D\`ej\'a Vu in Fixpoints of Logic Programs",
	Booktitle = "Proceedings of the Symposium on Logic Programming",
	Year = 1990,
	Address = "Cleveland, Ohio"}

@book{m:thet,
	Author = "David Maier",
	Title = "The Theory of Relational Databases",
	Publisher = "Computer Science Press",
	Address = "Rockville, Md.",
	Year = 1983,
	Annote = "Encyclopedia of relational theory."}

@techreport{msop:dev,
	Author = "David Maier and Jacob Stein and Allen Otis and
		  Alan Purdy",
	Title = "Development of an Object-Oriented DBMS",
	Institution = "Oregon Graduate Center",
	Year = 1986,
	Month = "April",
	Number = "CS/E-86-005",
	Annote = "From the abstract, goals and requirements include
		  an extensible data model that cpatures behavioral
		  semantics, no artificial bounds on the number or size
		  of database objects, database amenities (concurrency,
		  transactions, recovery, associative acces, authorization.)
		  Smalltalk is the basis, but it needs lots of work
		  before the database parts are satisfactory."}

@article{muv:ont,
	Author = "David Maier and Jeffrey D. Ullman and Moshe Y. Vardi",
	Title = "On the Foundations of the Universal Relational Model",
	Journal = "ACM Transactions on Database Systems",
	Volume = 9,
	Number = 2,
	Pages = "283--308",
	Year = 1984,
	Month = "June"}

@inproceedings{mps:wor,
	Author = "Alberto Marchetti-Spaccamela and Antonella Pelaggi and
		  Domenico Sacca",
	Title = "Worst-case Complexity Analysis of Methods for Logic
		 Query Implementation",
	Booktitle = "Proceedings of the ACM 
		     Symposium on Principles of Database Systems",
	Year = 1987,
	Month = "March",
	Address = "San Diego, California",
	Pages = "294--301",
	Annote = "The authors define all operations to have
		  unit cost except for set operations.  Letting
		  m be the number of edges and n be the number
		  of nodes, they give the bounds of m squared
		  for magic sets, and m times n for counting
		  if the underlying graph is acyclic.  They
		  give an extension of the counting method
		  that works for cyclic, but is m times (n cubed)."}



@techreport{m:col,
	Author = "John McCarthy",
	Title = "Coloring Maps and the {K}owalski Doctrine",
	Institution = "Department of Computer Science, Stanford
		       University",
	Month = "April",
	Year = 1982,
	Number = "STAN-CS-82-903",
	Annote = "Addresses the problem of whether logic plus
		  control is really enough, in the context of
		  graph coloring.  First, he notes that since
  		  any country with 3 or fewer neighbors is
		  trivially colorable with 4 colors, such countries
		  can be postponed.  This can be expressed in 
		  control by rearranging subgoals.  Next, he
		  discusses the ``Kempe'' transformation, by which
	  	  any four-neighbor country can be colored, although
		  it may require changing previously assigned
		  colors.  This  seems very difficult to express
		  in the paradigm of control applied to the original
		  program."}
		  

@article{m:som,
	Author = "Christopher S. Mellish",
	Title = "Some global optimizations for a prolog compiler",
	Journal = "J. Logic Programming",
	Year = 1985,
	Volume = 2,
	Number = 1,
	Pages = "43--66",
	Annote = "The basic premise is that, most of the time, prolog
		  programs are similar to conventional programs, that is,
		  they don't make use of nondeterminism.  By doing a
		  static global analysis one can automatically generate
		  mode declarations (+,-,o) and determinism declarations.  
		  These can subsequently be used by an optimizing compiler
		  to produce code similar to that produced by compiling
		  conventional languages, hence will run well on standard
		  machines and in integrated (multiple language)
		  environments."}

@inproceedings{mo:dis,
	Author = "T. H. Merrett and E. Otoo",
	Title = "Distribution models of relations",
	Booktitle = "Proceedings of the 5th International VLDB Conference",
	Month = "October",
	Year = 1979,
	Address = "Rio de Janeiro, Brazil",
	Pages = "418--425",
	Annote = "The idea is to view relations in a multidimensional
                  space, with one dimension per attribute.  Next, each
                  dimension is partitioned into some number of sectors.
                  Formulas for the sizes of operations are derived
                  by assuming that 1) distributions are uniform within
                  each sector, and 2) the number of values in each 
                  sector are known for all sectors."}

@article{mn:onr,
	Author = "Jack Minker and Jean M. Nicolas",
	Title = "On recursive axioms in relational databases",
	Journal = "Information Systems",
	Year = 1982,
	Volume = 8,
	Number = 1,
	Pages = "1--13",
	Annote = "Surveys a number of ways for dealing with recursive
		  axioms, including bottom-up, cutting cycles by 
		  instantiating relations, and subsumption.  Gives a
		  sufficient condition for the subsumption condition
		  to work.  Basically disallows permutations of
		  distinguished variables and sharing of nondistinguished
		  variables."}


@inproceedings{muv:des,
	Author = "Katherine Morris and Jeffrey D. Ullman and
		  Van Gelder, Allen",
	Title = "Design Overview of the {NAIL!} System",
	Booktitle = "Proceedings of the Third International Conference
		     on Logic Programming",
	Year = 1986,
	Annote = "No note."}

@article{mnsuv:yaw,
	Author = "Katherine Morris and Jeffrey F. Naughton and
	          Yatin Saraiya and Jeffrey D. Ullman and
		  Van Gelder, Allen",
	Title = "{YAWN!} ({Y}et {A}nother {W}indow On {NAIL!})",
	Journal = "Database Engineering",
	Month = "December",
	Year = "1987"}

@inproceedings{mfpr:mag,
	Author = "I. S. Mumick and S. Finkelstein and H. Pirahesh and
		  R. Ramakrishnan",
	Title = "Magic is Relevant",
	Booktitle = "Proceedings of the ACM SIGMOD International
		     Conference on Management of Data",
	Year = "1990",
	Address = "Atlantic City, New Jersey",
	Month = "May"}


@unpublished{mpr:ext,
	Author = "I. S. Mumick and H. Pirahesh and
		  R. Ramakrishnan",
	Title = "Duplicates and Aggregates in Deductive Databases",
	Year = "1990",
	Note = "Unpublished Manuscript."}


@techreport{myi:for,
	Author = "Masaki Murakami, Haruo Yokota, Hidenori Ito",	
	Title = "Formal semantics of a relational knowledge base",
	Institution = "ICOT Research Center",
	Year = 1985,
	Month = "December",
	Number = "TR--149",
	Annote = "A relational knowledge base is a relational
		  database in which the ``atoms'' can be terms and
		  the analogs of join, select, and project use
		  unification instead of equality.
		  
		  In this report they develop the semantics of
		  these operations.  Using a partial order, they
		  show that RBU (retrieval by unification) operations
		  are compositions of greatest lower bound operations."}

@article{p:onc,
	Author = "R. J. Parikh",
	Title = "On context-free languages",
	Journal = "Journal of the ACM",
	Volume = 13,
	Year = 1966,
	Pages = "570--581"}

@inproceedings{pw:par,
	Author = "F.C.N. Pereira and D.H.D. Warren",
	Title = "Parsing as deduction",
	Booktitle = "Proceedings of the twenty-first Annual Meeting of the
		Association for Computational Linguistics",
	Year = 1983,
	Page = "137--144"}

@article{p:ont,
	Author = "T. C. Przymusinski",
	Title = "On the semantics of stratified deductive databases
		 and logic programs",
	Journal = "Journal of Logic Programming",
	Year = 1986}

@phdthesis{n:neg,
	Author = "Lee Naish",
	Title = "Negation and Control in {P}rolog",
	School = "University of Melbourne",
        Year = 1985,
	Annote = "No note"}

@techreport{nt:the,
	Author = "L. Naish and J. A. Thom",
	Title = "The {MU-Prolog} Deductive Database",
	Number = "83/10",
	Institution = "Department of Computer Science, University 
		       of Melbourne",
	Month = "November",
	Year = "1983",
	Annote = "Not read."}

@inproceedings{ntr:con,
	Author = "Lee Naish and James A. Thom and Kotagiri
		  Ramamohanarao",
	Title = "Concurrent Database Updates in {P}rolog",
	Booktitle = "Proceedings of the Fourth International
		     Conference on Logic Programming",
	Year = 1987,
	Pages = "178--195",
	Annote = "An attempt at specifying an update operator
		  that allows correct implementation of 
		  concurrent updates and has a well-defined
		  ``declarative'' semantics.  Here, declarative
		  means that the update can be well defined
		  using pre and post conditions.  The operator
		  actually looks a lot like findall."}

@inproceedings{n:alo,
	Author = "Shamim Naqvi",
	Title = "A Logic for Negation in Database Systems",
	Booktitle = "Proceedings of the Workshop on Logic
	             and Databases",
        Year = 1986,
	Annote = "No note."}

@article{n:dat,
	Author = "Jeffrey F. Naughton",
	Title = "Data independent recursion in deductive databases",
	Journal = "Journal of Computer and System Sciences",
	Year = 1989,
	Month = "April",
	Pages = "259--289",
	Volume = 38,
	Number = 2,
	Annote = "No note"}

@inproceedings{n:datproc,
	Author = "Jeffrey F. Naughton",
	Title = "Data independent recursion in deductive databases",
	Booktitle = "Proceedings of the ACM 
		     Symposium on Principles of Database Systems",
	Year = 1986,
	Month = "March",
	Address = "Cambridge, Massachusetts",
	Pages = "267--279",
	Annote = "No note"}

@techreport{n:dattr,
	Author = "Jeffrey F. Naughton",
	Title = "Data independent recursion in deductive databases",
	Institution = "Stanford",
	Year = 1986,
	Month = "May",
	Number = "STAN-CS-86-1114",
	Annote = "No note"}


@unpublished{n:eva,
	Author = "Jeffrey F. Naughton",
	Title = "Evaluating One Sided Recursions",
	Year = 1987,
	Note = "Princeton TR, to appear."}

@techreport{n:comtr,
	Author = "Jeffrey F. Naughton",
	Title = "Compiling Separable Recursions",
	Year = 1988,
	Institution = "Princeton University",
	Number = "CS-TR-140-88"}

@inproceedings{n:com,
	Author = "Jeffrey F. Naughton",
	Title = "Compiling Separable Recursions",
	Booktitle = "Proceedings of the SIGMOD International
                     Symposium on Management of Data",
	Month = "May",
	Address = "Chicago, Illinois",
	Pages = "312--319",
	Year = 1988}

@techreport{n:bentr,
	Author = "Jeffrey F. Naughton",
	Title = "Benchmarking Multi-Rule Recursion Evaluation Strategies",
	Year = 1988,
	Institution = "Princeton University",
	Number = "CS-TR-141-88"}

@inproceedings{n:one,
	Author = "Jeffrey F. Naughton",
	Title = "One Sided Recursions",
	Booktitle = "Proceedings of the ACM 
		     Symposium on Principles of Database Systems",
	Pages = "340--348",
	Month = "March",
	Address = "San Diego, California",
	Year = 1987}

@techreport{n:opt,
	Author = "Jeffrey F. Naughton",
	Title = "Optimizing Function-Free Recursive Inference Rules",
	Institution = "Stanford",
	Year = 1986,
	Month = "May",
	Number = "STAN-CS-86-1114"}

@article{n:min,
	Author = "Jeffrey F. Naughton",
	Title = "Minimizing Function-Free Recursive Definitions",
	Journal = "Journal of the Association for Computing
                   Machinery",
	Volume = 36,
	Number = 1,
	Month = "January",
	Year = 1989,
	Pages = "69--91"
	}


@unpublished{n:par,
	Author = "Jeffrey F. Naughton",
	Title = "Parallel Logic: Project Documentation",
	Year = 1985,
	Note = "Unpublished manuscript, Stanford University."}

@inproceedings{n:red,
	Author = "Jeffrey F. Naughton",
	Title = "Redundancy in Function-free Recursive Inference Rules",
	Booktitle = "Proceedings of the IEEE Symposium on Logic Programming",
	Address = "Salt Lake City, Utah",
	Pages = "236--245",
	Year = 1986}

@unpublished{n:rep,
	Author = "Jeffrey F. Naughton",
	Title = "Representing Drawings and Programs by Relations",
	Year = 1987,
	Institution = "DEC Western Research Lab",
	Note = "Unpublished manuscript."}

@phdthesis{n:thesis,
	Author = "Jeffrey F. Naughton",
	Title = "Optimization of Recursive Database Query Languages",
	School = "Stanford University",
	Year = 1987}

@techreport{nr:aun,
	Author = "Jeffrey F. Naughton and Raghu Ramakrishnan",
	Title = "A Unified Approach to Logic Program Evaluation",
	Institution = "Computer Sciences Department, 
                       University of Wisconsin, Madison",
	Month = "November",
	Year = 1989,
	Number = "889"}

@inproceedings{nr:how,
	Author = "Jeffrey F. Naughton and Raghu Ramakrishnan",
	Title = "How to forget the past without repeating it",
	Booktitle = "Proceedings of the Sixteenth International Conference
                     on Very Large Data Bases",
	Month = "August",
	Year = 1990,
	Address = "Brisbane, Australia",
	Pages = "278--289"}

@inproceedings{ns:ade,
	Author = "Jeffrey F. Naughton and Yehoshua Sagiv",
	Title = "A Decidable Class of Bounded Recursions",
	Booktitle = "Proceedings of the ACM 
		     Symposium on Principles of Database Systems",
	Pages = "227--236",
	Year = 1987,
	Address = "San Diego, California",
	Month = "March",
	Annote = "Selected for special issue of the Journal of Logic
	        Programming."}

@inproceedings{nrsu:ari,
	Author = "Jeffrey F. Naughton and Raghu Ramakrishnan
	          and Yehoshua Sagiv and Jeffrey D. Ullman",
	Title = "Argument Reduction through Factoring",
	Year = 1989,
	Booktitle = "Proceedings of the Fifteenth International
		     Conference on Very Large Databases",
	Month = "August",
	Address = "Amsterdam, The Netherlands",
	Pages = "173--182"}

@inproceedings{nrsu:sigmod,
	Author = "Jeffrey F. Naughton 
	          and Raghu Ramakrishnan 
                  and Yehoshua Sagiv and Jeffrey D. Ullman",
	Title = "Efficient Evaluation of Right{-,} Left{-,} and Multi-Linear
	         Rules",
	Booktitle = "Proceedings of the ACM SIGMOD International Conference
	             on Management of Data",
	Year = 1989,
	Month = "May",
	Address = "Portland, Oregon",
        Pages = "235--242"}
	

@inproceedings{ns:min,
	Author = "Jeffrey F. Naughton and Yehoshua Sagiv",
	Title = "Minimizing Expansions of Recursions",
	Booktitle = "Resolution of Equations in Algebraic Structures",
	Volume = 1,
	Year = 1989,
	Pages = "321--349",
	Editor = "Hasan Ait-Kaci and Maurice Nivat",
	Publisher = "Academic Press, Inc.",
	Address = "San Diego, California"}

@techreport{ness:red,
	Author = "Linda Ness",
	Title = "Reducing Linear Recursive Relations to Transitive Closure",
	Institution = "University of Texas at Austin",
	Month = "November",
	Year = 1986,
	Number = "TR-86-25",
	Annote = "Shows that if you're willing to take cross products,
		  any linear recursion can be viewed as a transitive
		  closure.  Also has some results about how repeated
		  variables in the rule head can be handled."}

@inproceedings{or:sim,
	Author = "Frank Olken and Doron Rotem",
	Title = "Simple Random Sampling for Relational Databases",
	Booktitle = "Proceedings of the Twelfth International Conference
		     on Very Large Databases",
	Month = "August",
	Year = 1986,
	Address = "Kyoto, Japan",
	Pages = "160--169",
	Annote = "Considers questions such as when a relational 
                  operator applied to a random sample of a database
                  is a random sample of the output of the operator.
		  Gives performance of various schemes to produce
                  the samples.  Shows that of all the relational
		  operators, only select commutes with a random
                  sampling operator."}

@inproceedings{or:ran,
	Author = "Frank Olken and Doron Rotem",
	Title = "Random Sampling from {${\rm B}^+$}-trees",
	Booktitle = "Proceedings of the Fifteenth International Conference
		     on Very Large Databases",
	Month = "August",
	Year = 1989,
	Address = "Amsterdam, The Netherlands",
	Pages = "269--278",
	Annote = "Considers the problem of taking a random sample
                  based on an attribute on which there is a B+tree.
		  The main idea is to take a random walk from a root
		  to a leave, using acceptance/rejection at each 
                  level.  Essentially, you are sampling from the corresponding
                  full B+tree, and ignoring paths that don't really 
                  exist.  They conclude that the best method includes
                  early abort (don't wait until the leaf to decide
                  if a path is valid) along with batch (take a bunch of
                  samples for each path from root to leaf, to take
                  advantage of caching of the B+tree roots on the
                  path.)"}

@inproceedings{orx:ran,
	Author = "Frank Olken and Doron Rotem and Ping Xu",
	Title = "Random Sampling from Hash Files",
	Booktitle = "Proceedings of the ACM SIGMOD Conference on Management
		     of Data",
	Year = 1990,
	Month = "May",
	Address = "Atlantic City, New Jersey",
	Pages = "375-386",
	Annote = "Straightforward stuff, but a good analysis for the
                  performance.  The main trick is to guarantee uniform
                  inclusion probabilities in the presence of varying
                  numbers of records in hash buckets."}


@inproceedings{pl:dat,
	Author = "Michael L. Powell and Mark A. Linton",
	Title = "Database Support for Programming Environments",
	Booktitle = "Proceedings of the Engineering Design
                     Applications of ACM-IEEE Database Week",
	Year = 1983,
	Month = "May",
	Annote = "No note."}

@inproceedings{r:par,
	Author = "Raghu Ramakrishnan",
	Title = "Parallelism in Logic Programs",
	Booktitle = "Proceedings of the ACM Symposium on Principles of
		     Programming Languages",
	Address =  "San Francisco, California",
	Year = 1990}	 

@inproceedings{r:mag,
	Author = "Raghu Ramakrishnan",
	Title = "Magic Templates: A Spellbinding Approach to Logic
		 Programs",
	Booktitle = "Proceedings of the International Conference on Logic
		     Programming",
	Year = 1988,
	Pages = "140--159",
	Month = "August",
	Address = "Seattle, Washington",
	Annote = "Generalizes Magic Sets to do bottom-up even
	          with uncovered variables and so forth.  Involves
		  harder-to-test termination conditions for
		  bottom-up evaluation, but could be very efficient
		  in that it automatically produces dyanamic
		  programming algorithms."}

@inproceedings{rbk:opt,
	Author = "Raghu Ramakrishnan and Catriel Beeri and Ravi
	          Krishnamurthy",
	Title = "Optimizing Existential Datalog Queries",
	Booktitle = "Proceedings of the ACM 
	             Symposium on Principles of Database Systems",
	Year = 1988,
	Month = "March",
	Pages = "89--102",
	Address = "Austin, Texas",
	Annote = "No note."}

@inproceedings{rbs:saf,
	Author = "Raghu Ramakrishnan and Francois Bancilhon and
	          Avi Silberschatz",
	Title = "Safety of Recursive Horn Clauses with Infinite
		 Relations",
	Booktitle = "Proceedings of the ACM 
		     Symposium on Principles of Database Systems",
        Year = 1987,
	Month = "March",
	Address = "San Diego, California",
	Pages = "328--339",
        Annote = "No note"}

@inproceedings{rsuv:pro,
	Author = "Raghu Ramakrishnan and Yehoshua Sagiv and Jeffrey
	          D. Ullman and Moshe Vardi",
	Title = "Proof-Tree Transformation Theorems and Their
	         Applications",
	Booktitle = "Proceedings of the ACM Symposium on Principles
	             of Database Systems",
	Year = 1989,
	Month = "March",
	Address = "Philadelphia, Pensylvannia"}

@inproceedings{r:how,
	Author = "Abhiram G. Ranade",
	Title = "How to emulate shared memory",
	Booktitle = "Proceedings of the 28th Annual
	             Symposium on Computer Science",
	Year = 1987,
	Pages = "185--194"}

@inproceedings{r:tra,
	Author = "U.S. Reddy",
	Title = "Transformation of logic programs into functional programs",
	Booktitle = "Proceedings of the 
	Symposium on Logic Programming",
	Year = 1984,
	Pages = "187--196",
	Address = "Salt Lake City, Utah",
	Month = "September",
	Annote = "Introduces a notion of modes and rule evaluation
		  that seems to be one of the first versions of adornments
		  and sideways information passing. Presents techniques
		  for inferring that a query form is functional, i.e.
		  if the bound arguments are instantiated, they uniquely
		  determine the free arguments. Presents sufficient 
		  conditions that are similar to those in Debray-Warren
		  paper on functional programs; can deal with programs
		  that only produce ground terms. Techniques generalized
		  in Maher-Ramakrishnan Deja Vu paper; non-ground
		  computations covered as well."}


@incollection{r:onc,
	Author = "Raymond Reiter",
	Title = "On closed world databases",
	Booktitle = "Logic and Databases",
	Publisher = "Plenum Press",
	Year = 1978,
	Editor = "Herve Gallaire and Jack Minker",
	Pages = "55--76",
	Address = "New York",
	Annote = "Good development of terminology.  Shows that Horn IDB's
		  under the closed world assumption are always consistent."}

@incollection{r:ded,
	Author = "Raymond Reiter",
	Title = "Deductive question-answering on relational databases",
	Booktitle = "Logic and Databases",
	Publisher = "Plenum Press",
	Year = 1978,
	Editor = "H. Gallaire and J. Minker",
	Pages = "149--177",
	Address = "New York",
	Annote = "Shows how to ``compile'' queries so that the unification
		  is done at compile time rather than at query time."}

@unpublished{r:rec,
	Author = "Dominique Roelants",
	Title = "Recursive rules in logic databases",
	Year = 1987,
	Month = "March",
	Note = "Unpublished manuscript, Philips Research Laboratory,
	        Brussels, Belgium",
	Annote = "A survey.  Classifies algorithms depending on 
	          whether they terminate on solutions, on 
		  subqueries, or both.  It's not clear what
		  all this means, but it is a good survey
		  of a bunch of methods."}

@article{rlk:the,
	Author = "J. Rohmer and R. Lescoeur and J. M. Kerisit",
	Title = "The {A}lexander Method --- A technique for the 
	         processing of Recursive Axioms in Deductive
		 Database Queries",
	Journal = "New Generation Computing",
	Volume = 4,
	Pages = "522--528",
	Year = 1986,
	Annote = "not read"}


@inproceedings{rhdm:tra,
	Author = "Arnon Rosenthal and Sandra Heiler and Umeshwar Dayal
		  and Frank Manola",
	Title = "Traversal Recursion: A Practical Approach to Supporting
		 Recursive Applications",
	Booktitle = "Proceedings of the ACM-SIGMOD International Conference
		     on Management of Data",
	Year = 1986,
	Month = "June",
	Address = "Washington, D.C.",
	Annote = "The goal of this work is to add recursion to existing
		  db systems without a lot of changes.  (Here, adding
		  recursion to the PROBE system, which supports
		  recursion and complex objects.)  Traversal recursion
		  is the kind of recursion the authors feel is most
		  useful in engineering applications.  Roughly, it is
		  graph traversal, possibly with aggregation operators
		  applied to the paths traversed.  (They claim that
		  Prolog can't match the performance of their system
		  if the query involves aggregation or arithmetic.)
		  
		  All of the examples are linear recursive.  They propose
		  three evaluation algorithms: in memory (read the graph
		  into memory, then do one of), iterative (semi-naive
		  bottom-up in Bancilhon's terminology), and traversal.  The
		  last is just following paths through the graph, as a
		  procedural language would do."}

@inproceedings{rs:the,
	Author = "Lawrence A. Rowe and Michael R. Stonebraker",
	Title ="The {POSTGRES} Data Model",
	Booktitle = "Proceedings of the 13th VLDB Conference",
	Year = 1987,
	Pages = "83--96",
	Month = "September",
	Address = "Brighton, England",
	Annote = "The data model is a relational model
		  extended by user-defined ADT's, and attribute
		  and procedure inheritance.  These mechanisms
		  can be used to simulate lots of semantic and
		  object-oriented data modeling constructs including
		  aggregation and generalization, complex objects
		  with shared subobjects, and attributes that
		  reference tuples in other relations."}

@inproceedings{s:lin,
	Author = "Yatin Saraiya",
	Title = "Linearizing nonlinear recursions in polynomial time",
	Booktitle = "Proceedings of the ACM SIGACT-SIGART-SIGMOD Symposium
		     on Principles of Database Systems",
	Pages = "182--189",
	Address = "Philadelphia, Pennsylvania",
	Month = "March",
	Year = "1989"}

@inproceedings{sz:ont,
	Author = "Domenico Sacca and Carlo Zaniolo",
	Title = "On the Implementation of a Simple Class of Logic
		 Queries for Databases",
	Booktitle = "Proceedings of the 5th ACM  Symposium
		     on Principles of Database Systems",
	Year = 1986,
	Month = "March",
	Address = "Cambridge, Massachusetts",
	Annote = "An initial stab at generalizing counting and magic
		  beyond Bancilhon et. al"}

@inproceedings{sz:the,
	Author = "Domenico Sacca and Carlo Zaniolo",
	Title = "The Generalized Counting Methods for Recursive
		 Logic Queries",
	Booktitle = "Proceedings of the First International Conference
		     on Database Theory",
	Year = 1986}

@inproceedings{sz:mag,
	Author = "Domenico Sacca and Carlo Zaniolo",
	Title = "Magic Counting Methods",
	Booktitle = "Proceedings of the ACM-SIGMOD Symposium on the
		     Management of Data",
	Year = 1987,
	Pages = "49--59",
	Month = "June",
	Address = "San Fransisco, California",
	Annote = "Notes that because Magic Sets is $O(n^2)$, and
		  Counting is $O(ne)$, if you combine the two
		  you can get the best (worst?) of each."}

@article{s:ani,
	Author = "L. Schmitz",
	Title = "An Improved Transitive Closure Algorithm",
	Journal = "Computing",
	Volume = 30,
	Year = 1983,
	Pages = "359--371"}

@inproceedings{s:ont,
	Author = "H. Seki",
	Title = "On the power of {A}lexander templates",
	Booktitle = "Proceedings of the Eighth ACM SIGACT-SIGMOD-SIGART
		     Symposium on Principles of Database Systems",
	Month = "March",
	Year = 1989,
	Address = "Philadelphia, Pennsylvania",
	Pages = "150--159"}

@inproceedings{s:eff,
	Author = "Timos K.~Sellis",
	Title = "Efficiently Supporting Procedures in Relational Database
		 Systems",
	Booktitle = "Proceedings of the ACM-SIGMOD Symposium on the
		     Management of Data",
	Year = 1987,
	Month = "June",
	Address = "San Fransisco, California",
	Pages = "278--291",
	Annote = "Essentially discusses how to optimize QUEL+, the query
		  language for POSTGRES.  The new material here is an
		  attempt to deal with fields that contain quel queries
		  rather than data.  He proposes an extension to the QUEL
		  decomposition algorithm --- it's most salient feature
		  seems to be that it postpones referring to fields that
		  contain QUEL procedures as long as possible on the
		  hope that earlier parts of the query will reduce
		  the number of tuples with attributes that have
		  to be evaluated.
		  
		  He says that some kind of caching is essential
		  for good performance, and touches on things
		  like cache size and replacement strategies.
		  
		  On a related matter he discusses what he calls
		  ``partial indexing'' for indexing results of
		  QUEL procedure fields.  Once a query causes 
		  part of the relation for the QUEL field to
		  be built an index is built for the materialized
		  portion, along with a predicate to tell subsequent
		  queries whether the index is of use or not."}

@inproceedings{s:und,
	Author = "Oded Shmueli",
	Title = "Decidability and Expressiveness aspects of Logic Queries",
	Booktitle = "Proceedings of the ACM Symposium on Principles of
                     Database Systems",
	Pages = "237--249",
	Address = "San Diego, California",
	Month = "March",
	Year = 1987}

@inproceedings{sn:set,
	Author = "Oded Shmueli and Shamim Naqvi",
	Title = "Set Grouping and Layering in Horn Clause Programs",
	Booktitle = "Proceedings of the Fourth International
		     Conference on Logic Programming",
	Year = 1987,
	Pages = "152--177",
	Annote = "Main result is that there exist programs
	          with minimal models that have no layered
		  equivalent."}

@book{s:seq,
	Author = "David Siegmund",
	Title = "Sequential Analysis",
	Publisher = "Springer-Verlag",
	Address = "New York, New York",
	Year = 1985}

@inproceedings{ss:mag,
	Author = "Seppo Sippu and Eljas {Soisalon-Soinen}",
	Title = "An Optimization Strategy for Recursive Queries
		 in Logic Databases",
	Booktitle = "Proceedings of the Fourth International Conference
		     on Data Engineering",
	Year = 1988,
	Address = "Los Angeles, California"}

@techreport{sz:int,
	Author = "Karen E. Smith and Stanley B. Zdonik",
	Title = "Intermedia: A Case Study of the Differences Between
		 Relational and Object-Oriented Database Systems",
	Institution = "Brown University",
	Month = "July",
	Year = 1987,
	Number = "CS-87-18",
	Annote = "	Intermedia is an object oriented document
			management system.  This article describes
			the problems with storing the data for such
			a system in a relational database.  Their
			main complaints seem to be 1) no structured
			objects 2) data must be copied into application
			program before it is manipulated 3) you can
			do in one object-oriented query things that
			would take many relational queries.

			Much of that is true, but is more an argument
			about the shortcomings of the relational model
			than the plusses of an OO model.  Again, it seems
			to me that if you have a good programmer that
			has written methods for exactly the queries you
			wish to ask, OO is great.  I'm not convinced about
			the ease with which you can ``ask any question.''"}

@article{s:typ,
	Author = "Lawrence Snyder",
	Title = "Type Architectures, Shared Memory, and the
	         Corollary of Modest Potential",
	Journal = "Annual Reviews of Computer Science",
	Year = 1986,
	Volume = 1,
	Pages = "289--317",
	Annote = "The corollary of modest potential states
	          that, for super-linear problems, adding
		  processors will allow only modestly larger
		  problems to be solved.   The type architecture
		  is an alternative to the P-RAM, arguably one
		  that models true costs of parallel computation
		  more accurately."}


@inproceedings{sr:postgres,
	Author = "Michael Stonebraker and Lawrence A. Rowe",
	Title = "The Design of {POSTGRES}",
	Booktitle = "Proceedings of the ACM SIGMOD International
		     Conference on Management of Data",
	Year = 1986,
	Pages = "340--355",
	Address = "Washington, D.C.",
	Month = "June",
	Annote = "Postgres extends INGRES by allowing better support
		  for complex objects (an ``object oriented approach''),
		  extendible data types and operators and access
		  methods (also ``object oriented''), inferencing through
		  triggers,  simplified crash recovery by maintaining the
		  log as data in the database, and a design that can
		  take advantage of optical disks and multiprocessor
		  workstations.
		  
		  It seems like a framework you can throw almost anything
		  on top of - in particular, fields can include POSTQUEL,
		  which, along with iteration, allows object-oriented
		  programming and logic programming as suggested by
		  Bancilhon in his ``logic programming cocktail'' paper."}


@techreport{sgg:con,
	Author = "David E. Smith and Michael R. Genesereth and
		  Matthew L. Ginsberg",
	Title = "Controlling Recursive Inference",
	Institution = "Stanford",
	Year = 1985,
	Month = "June",
	Number = "HPP 84-6",
	Annote = "This paper discusses some interpretive ways of
	          evaluating recursively defined predicates.  It
		  dodges some tough questions --- for example,
		  it uses ``transitive rule'' and ``optimal''
		  without definition.  Also, no mention of bound/free
		  information.  
		  
		  In discussing function free cases, they note that
		  subsumption sometimes works, show that reformulation
		  isn't satisfactory, and beat on the idea that
		  you can avoid redundancy by ``plugging in'' answers
		  to one subgoal to isomorphic subgoals.
		  
		  The treatment of function symbols is even more
		  ad-hoc, rehashing some program termination
		  results but not showing how to derive the
		  invariants.
		  
		  Finally, they note that Ullman TR1000 is 
		  incorrect, and would add nothing to their
		  results if it was."}

@article{sg:ord,
	Author = "David E. Smith and Michael R. Genesereth",
	Title = "Ordering Conjunctive Queries",
	Journal = "Artificial Intelligence",
	Volume = 26,
	Year = 1985,
	Pages = "171--215"}

@techreport{sz:imp,
	Author = "Domenico Sacca and Carlo Zaniolo",
	Title = "Implementing Recursive Logic Queries with Function Symbols",
	Institution = "MCC",
	Year = 1986,
	Number = "DB-065-86"}

@article{s:onb,
	Author = "Yehoshua Sagiv",
	Title = "On Bounded Database Schemes and Bounded Horn-Clause
	         Programs",
	Journal = "SIAM Journal of Computing",
	Volume = 17,
	Number = 1,
	Month = "February",
	Year = 1988,
	Pages = "1--22",
	Annote = "Gives early results about boundedness of SIRUP's"}

@inproceedings{s:pods,
	Author = "Yehoshua Sagiv",
	Title = "On computing restricted projections of representative 
		 instances",
	Booktitle = "Proceedings of the ACM Symposium
		     on Principles of Database Systems",
	Year = 1985,
	Month = "March",
	Address = "Portland, Oregon",
	Pages = "171--180",
	Annote = "no note"}

@inproceedings{sagiv:opt,
	Author = "Yehoshua Sagiv",
	Title = "Optimizing Datalog Programs",
	Booktitle = "Foundations of Deductive Databases and 
	             Logic Programming",
	Editor = "Jack Minker",
	Publisher = "Morgan Kaufmann",
	Address = "Los Altos, California, 94022",
	Pages = "659--698",
	Year = 1988,
	Annote = "no note"}

@techreport{su:com,
	Author = "Yehoshua Sagiv and Jeffrey D. Ullman",
	Title = "Complexity of a top-down capture rule",
	Institution = "Stanford",
	Year = 1984,
	Number = "STAN--CS--84--1009"}

@article{sy:equ,
	Author = "Yehoshua Sagiv and Mihalis Yannakakis",
	Title = "Equivalences among relational expressions with the
 		 union and difference operators",
	Journal = "Journal of the ACM",
	Year = 1980,
	Volume = 27,
	Number = 4,
	Month = "October",
	Pages = "633--655",
	Annote = "Extends the paper by ASU by considering relational
		  expressions containing union and difference.  A
		  basic result is that one union of tableaux if
		  contained in another if and only if each tableau
		  of the first is contained in some tableau of
		  the second.  Proves that finding the minimal
		  tableau for a query equivalent to a series
		  of joins followed by a projection is NP-complete
		  (reduction from exact cover).  Also gives some
		  cases where there is a polynomial algorithm for
		  containment.  Finally, shows that containment 
		  unions of tableaux is $\Pi^P_2$-complete."}

@inproceedings{st:rec,
	Author = "Hajime Sawamura and Taku Takeshima",
	Title = "Recursive unsolvability of determinacy, solvable cases of
		 determinacy, and their applications to prolog optimization",
	Booktitle = "Proceedings of the IEEE Symposium on Logic
		     Programming",
	Year = 1985,
	Pages = "200--207",
	Annote = "The authors define a goal to be deterministic if when it
	 	  is called at most one clause of its defining clauses
		  succeeds, and when it is backtracked it never succeeds 
		  again.  (can only return one answer.)  Because the authors
		  are working with prolog, their optimizations are of the
		  type ``in H :- S, P, R, P, if P is deterministic and has
		  no side effects, then the second P can be removed.  They
		  also discuss inline expansion and automatic insertion of
		  cuts."}


@inproceedings{ss:opt,
	Author = "Timos K. Sellis and Leonard Shapiro",
	Title = "Optimization of Extended Database Query Languages",
	Booktitle = "Proceedings of the ACM-SIGMOD International Conference
		     on Management of Data",
	Year = 1985,
	Pages = "424--436",
	Annote = "Basically a paper on optimizing QUEL*, which is QUEL with
		  a ``do it until no changes'' operator.  The major point
		  seems to be that in contrast to QUEL, QUEL* queries can
		  cause a sequence of QUEL queriers, and optimization can
		  be done over the sequence.  Principle optimizations 
		  discussed are removal of loop-invariants, caching of
		  common subexpression results, and reordering joins and
		  selections."}

@article{s:dis,
	Author = "Alan Jay Smith",
	Title = "Disk Cache --- Miss Ratio Analysis and Design
		 Considerations",
	Journal = "ACM Transactions on Computer Systems",
	Year = 1985,
	Volume = 3,
	Number = 3,
	Pagers = "161--203",
	Annote = "Talks about disk cache design.  Disk cache refers
		  to saving disk I/O's by saving disk pages in
		  the cache.  The savings occurs when a page
		  is referenced frequently."}

@techreport{s:asu,
	Author = "Ehud Y. Shapiro",
	Title = "A subset of Concurrent Prolog and Its Interpreter",
	Institution = "ICOT Research Center",
	Year = 1983,
	Month = "February",
	Number = "TR-003",
	Annote = "Another scheme for OR-Parallelism that relies on
		  a single producer per variable, enforced by user
		  annotations.  Got this from DeGroot."}

@inproceedings{sm:inf,
	Author = "S. E. Shapiro and D. P. McKay",
	Title = "Inference with recursive rules",
	Booktitle = "Proceedings of the 1st Annual National Conference
		     on Artificial Intelligence",
	Year = 1980}

@inproceedings{s:opt,
	Author = "Arun Swami",
	Title  = "Optimization of Large Join Queries: Combining
		  Heuristics and Combinatorial Techniques",
	Booktitle = "Proceedings of the ACM-SIGMOD Conference on
		     Management of Data",
	Year = 1989,
	Month = "June",
	Address = "Portland, Oregon",
	Pages = "367--376"}

@inproceedings{sg:opt,
	Author = "Arun Swami and Anoop Gupta",
	Title = "Optimization of Large Join Queries",
	Booktitle = "Proceedings of the ACM-SIGMOD Conference on
	             Management of Data",
	Year = 1988,
	Pages = "8--17",
	Month = "May",
	Address = "Chicago, Illinois",
	Annote = "Compares methods for optimizing large (10-100 join)
	          join queries.  They only consider linear joins.  The
		  optimization strategies considered include Simulated
		  Annealing and several variants of local optimization.
		  The best turned out to be Iterative Improvement,
		  which just generates a random state, hill-climbs
		  to a local minimum, then generates a new random
		  state to see if it can do better.  The joins
		  were randomly generated, and the optmization
		  methods were compared by using some weighted
		  average of how good it was on average minus
		  how bad it was in the worst case."}

@inproceedings{ts:unf,
	Author = "Hisao Tamaki and Taisuke Sato",
	Title = "Unfold/Fold Transformations of Logic Programs",
	Booktitle = "Proceedings of the Second International Conference
		     on Logic Programming",
	Month = "July",
	Year = "1984",
	Address = "Uppsala, Sweden",
	Pages = "127--138",
	Annote = "not read, but from abstract it appears to prove
		  that a subset of fold/unfold transformations can
		  be proven safe (preserves the least Herbrand
		  model.)"}


@article{t:dep,
	Author = "Robert E. Tarjan",
	Title = "Depth first search and linear graph algorithms",
	Journal = "SIAM Journal of Computing",
	Year = 1972,
	Volume = 1,
	Number = 2,
	Pages = "146--160"}

@article{t:fas,
	Author = "Robert E. Tarjan",
	Title = "Fast algorithms for solving path problems",
	Journal = "Journal of the ACM",
	Number = 28,
	Pages = "594--614",
	Year = 1981}

@inproceedings{ton:ded,
	Author = "Shalom Tsur and Frank Olken and D. Naor",
	Title = "Deductive Databases for Genomic Mapping",
	Booktitle = "Proceedings of the NACLP Workshop on Applications
                     of Deductive Databases",
	City = "Austin, Texas",
	Month = "November",
	Year = 1990}

@inproceedings{tz:ani,
	Author = "Shalom Tsur and Carlo Zaniolo",
	Title = "An Implementation of {GEM} --- supporting a semantic
		 data model on a relational back-end",
	Booktitle = "Proceedings of the ACM-SIGMOD Conference on
		     Management of Data",
	Year = 1984,
	Pages = "286--295",
	Annote = "Discusses implementing GEM using the IDM 500 and QUEL
		  as a back end.  The most interesting part is the
		  conclusion.  It is relatively easy to put richer
		  semantic models on top of relational, as in the entity-
		  relationship model.  However, some of the innards of
		  the relational system need to be changed for efficiency.
		  One needs binary data types and bit operations, 
		  procedural operations, and better control of clustering
		  of data for efficiency.  (Although the authors don't
		  mention it, it seems to me that implementing surrogates
		  as unique fields, and doing a join to get the connection,
		  seems a little hokey.  Maybe Linton's tuple maps?)"}

@inproceedings{tz:ldl,
	Author = "Shalom Tsur and Carlo Zaniolo",
	Title = "{LDL}: A Logic-Based Data-Language",
	Booktitle = "Proceedings of the Twelfth International
	 	     Conference on Very Large Data Bases",
	Year = 1986,
	Pages = "33--41",
	Address = "Kyoto, Japan",
	Month = "August",
	Annote = "A good introduction to ``why logic-based data
	  	  languages.''"}    

@book{u:oldbook,
	Author = "Jeffrey D. Ullman",
	Title = "Principles of Database Systems",
	Publisher = "Computer Science Press",
	City = "Rockville",
	State = "Maryland",
	Year = 1982,
	Annote = "No note."}

@book{u:pri,
	Author = "Jeffrey D. Ullman",
	Title = "Principles of Database and Knowledge-Base Systems",
	Year = 1988,
	Publisher = "Computer Science Press",
	City = "Rockville",
	State = "Maryland",
	Volume = 1}

@article{u:imp,
	Author = "Jeffrey D. Ullman",
	Title = "Implementation of Logical Query Languages for Databases",
	Journal = "ACM Transactions on Database Systems",
	Year = 1985,
	Volume = 10,
	Number = 4,
	Month = "September",
	Pages = "289--321",
	Annote = "The first NAIL! paper.  Introduces capture rules,
		  and gives some simple ones for proving termination
		  by induction on argument sizes.  Introduces the
		  rule/goal graph with adornments"
	}



@inproceedings{uv:par,
	Author = "Jeffrey D. Ullman and Van Gelder, Allen",
	Title = "Parallel Complexity of Logical Query Programs",
	Booktitle = "Proceedings of the 27th Foundations of Computer Science
		     Conference",
	Year = 1986,
	Annote = "Also have TR, STAN-CS-85-1089, with complete proofs."}

@techreport{uv:tes,
	Author = "Jeffrey D. Ullman and Van Gelder, Allen",
	Title = "Testing Applicability of Top-Down Capture Rules",
        Institution = "Stanford University",
	Number = "STAN-CS-85-1046",
	Year = 1985,
        Annote = "No note"}

@inproceedings{u:bot,
	Author = "Jeffrey D. Ullman",
	Title = "Bottom-up Beats Top-Down for Datalog",
	Booktitle = "Proceedings of the Eighth ACM SIGACT-SIGMOD-SIGART
		     Symposium on Principles of Database Systems",
	Month = "March",
	Year = 1989,
	Pages = "140--149",
	Address = "Philadelphia, Pennsylvania"}

@inproceedings{uw:how,
	Author = "Eli Upfal and Avi Wigderson",
	Title = "How to share memory in a distributed system",
	Booktitle = "Proceedings of the Sixteenth ACM STOC",
	Year = 1984,
	Pages = "171--180",
	Annote = "Show how to simulate a PRAM step on a network in
	          $O(\log n (\log\log n)^2)$ steps.  This is
		  a deterministic bound, involving multiple copies
		  of data items.  Also shows a lower bound of
		  $\Omega(\frac{\log n}{\log\log n}$.
		  "}

@inproceedings{vb:ont,
	Author = "Patrick Valduriez and Haran Boral",
	Title = "Evaluation of Recursive Queries Using Join Indices",
	Booktitle = "Proceedings of the First International Conference on
		     Expert Database Systems",
	Year = 1986}


@inproceedings{v:ame,
	Author = "Van Gelder, Allen",
	Title = "A Message Passing Framework for Logical Query Evaluation",
	Booktitle = "Proceedings of the ACM SIGMOD International Conference
		     on Management of Data",
	Year = 1986,
	Month = "May",
	Address = "Washington, DC",
	Pages = "349--362"}

@inproceedings{v:neg,
	Author = "Van Gelder, Allen",
	Title = "Negation as failure using tight derivations for
	         general logic programs",
	Booktitle = "Proceedings of the IEEE Symposium on Logic 
		     Programming",
	Year = 1986,
	Pages = "127--139",
	Annote = "No note."}

@inproceedings{v:dec,
	Author = "Moshe Y. Vardi",
	Title = "Decidability and Undecidablity Results for
		 Boundedness of Linear Recursive Queries",
	Booktitle = "Proceedings of the Seventh ACM 
		      Symposium on 
		     Principles of Database Systems",
	Year = 1988,
	Month = "March",
	Address = "Austin, Texas",
	Pages = "341--351",
	Annote = "Shows that boundedness is undecidable for linear
	          programs with one binary IDB predicate.  Also
		  shows that boundedness is NP-Complete if the
		  single IDB predicate is binary and the program
		  has only one recursive rule."}

@inproceedings{v:dat,
	Author = "Laurent Vieille",
	Title = "Database Complete Proof Procedures Based on
		 {SLD}-Resolution",
	Booktitle = "Proceedings of the Fourth International
		     Conference on Logic Programming",
	Year = 1987,
	Pages = "74--103",
	Annote = "Basically a patch to QSQ.  ``Database complete''
	          means that it returns all answers in datalog
		  and is guaranteed to terminate.  Another paper
		  that (like the Generalized Magic Sets papers)
		  seems to think that ``focus on relevant data''
		  is all there is.  For example, the algorithm
		  is $O(n^2)$ on selections on the transitive 
		  closure, whereas one-sided algorithms are
		  O(n)."}



@inproceedings{v:rec,
	Author = "Laurent Vieille",
	Title = "Recursive axioms in Deductive Databases: The Query-subquery
		 Approach",
	Booktitle = "Proceedings of the First International Conference on
		     Expert Database Systems",
	Address = "Charleston, South Carolina",
	Year = 1986,
	Pages = "179--193"}


@article{w:amo,
	Author = "H. S. Warren",
	Title = "A Modification of {W}arshall's Algorithm for
	         the Transitive Closure of Binary Relations",
	Journal = "Communications of the ACM",
	Volume = 18,
	Number = 4,
	Month = "April",
	Year = 1975,
	Pages = "218--220"}


@article{w:ath,
	Author = "S. Warshall",
	Title = "A Theorem on Boolean Matrices",
	Journal = "Journal of the ACM",
	Volume = 9,
	Number = 1,
	Month = "January",
	Year = 1962,
	Pages = "11-12"}

@book{w:seq,
	Author = "{G. Barrie} Wetherill",
	Title = "Sequential Methods in Statistics",
	Publisher = "John Wiley and Sons, Inc.",
	Address = "New York, New York",
	Year = 1966}

@article{wvt:ali,
	Author = "Kyu-Young Whang and Brad T. Vander-Zanden and 
                  Howard M. Taylor",
	Title = "A Linear-Time Probabilistic Counting Algorithm for
                 Database Applications",
	Journal = "ACM Transactions on Database Systems",
	Volume = 15,
	Number = 2,
	Month = "June",
	Year = 1990,
	Pages = "208--229",
	Annote = "Basic idea: count number of distinct tuples in
                  a projection by scan+hashing.  The interesting
                  point is that a hash table much smaller than that
                  required to hold all distinct elements suffices
                  for high accuracy."}

@inproceedings{ws:sha,
	Author = "O. Wolfson and A. Silberschatz",
	Title = "Sharing the Load of Logic Program Evaluations",
	Booktitle = "Proceedings of the  7th ACM SIGMOD-SIGACT-SIGART 
		   Symposium on Principles of Database Systems",
	Address = "Philadelphia, Pennsylvania",
	Month = "March",
	Year = "1989"}

@techreport{yi:amo,
	Author = "Haruo Yokota, Hidenori Ito",	
	Title = "A Model and an Architecture for a Relational Knowledge
		 Base",
	Institution = "ICOT Research Center",
	Year = 1985,
	Month = "November",
	Number = "TR--141",
	Annote = "A relational knowledge base is a relational database
		  in which ``atoms'' can actually be terms, that is,
		  structures which can contain variables.  The hope is 
		  that this will allow more general data to be handled
		  efficiently.  Terms can also be rules.
		  
		  The most interesting idea is that, by introducing
		  and order on these terms, many relational database
		  algorithms can be used, i.e., the basic operations
		  are selections, projections, and joins, with equality
		  replaced by unifiability.  This lets database 
		  techniques for ``getting things to meet'' can be
		  used in the knowledge base.
		  
		  This paper gives some details on a machine to 
		  implement this. It consists of a number
		  of unification processors, a multi-port paged
		  memory,  a switching network, and a control
		  processor."}
		  



@techreport{ysi:ded,
	Author = "Haruo Yokota, K\={o} Sakaai, Hidenori Ito",	
	Title = "Deductive Database System based on Unit Resolution",
	Institution = "ICOT Research Center",
	Year = 1985,
	Month = "June",
	Number = "TR--123",
	Annote = "For ICOT, a deductive database system is a relational
		  database system plus horn clauses.  In this paper they
		  note that recursive queries can be handled bottom-up, 
		  and that top-down doesn't necessarily converge.
		  
		  Marginally more interesting is their division between
		  intensional and extensional processors.  The intensional
		  processor developes ``plans,'' which are executed by
		  the extensional processor.  If the query involves
		  recursion, then the plan includes instructions for
		  the extensional processor to evaluate the fixed-point.
		  The rational is that transferring data is expensive,
		  and that the extensional processor is optimized for
		  larger amounts of data anyway.
		  
		  They also discuss ``setting resolution,'' a strategy 
		  that enumerates the resolvents that could possibly
		  appear in some derivation of a given goal."}

@inproceedings{yhh:cla,
	Author = "Cheong Youn and Lawrence Henschen and Jiawei Han",
	Title = "Classification of Recursive Formulas in Deductive
		 Databases",
	Booktitle = "Proceedings of the SIGMOD International Conference
		     on Management of Data",
	Year = 1988,
	Month = "June",
	Pages = "320--328",
	Address = "Chicago, Illinois",
	Annote = "Using Ioannidis's alpha graph, the authors classify
		  single rule linear recursive formulas.  The only
		  transformations they consider are expanding the
		  recursion."}

@inproceedings{z:saf,
	Author = "Carlo Zaniolo",
	Title = "Safety and Compilation of Non-Recursive Horn
		 Clauses",
	Booktitle = "Proceedings of the First International
		     Conference on Expert Database Systems",
        Year = 1986,
        Annote = "No note"}
		  

@inproceedings{z:the,
	Author = "Carlo Zaniolo",
	Title = "The Database Language {GEM}",
	Booktitle = "Proceedings of the ACM SIGMOD Conference",
	Year = 1983,
	Pages = "207--218",
	Annote = "An easy-to-use extension of QUEL, designed to 
		  provide more sematic richness.  Supports the notion
		  of entities with surrogates (references to other
		  entities), aggregation, generalization (entity
		  families, that is, disjoint alternatives for
		  the basic entity), null values, and set-valued attributes.
		  
		  Uses ``functional joins'' to clean up queries, i.e., the
		  user can write ``SALES.Item.Name'' instead of joining
		  SALES and ITEMS."}

@inproceedings{z:ther,
	Author = "Carlo Zaniolo",
	Title = "The Representation and Deductive Retrieval
		 of Complex Objects",
	Booktitle = "Proceedings of the Eleventh International
		     Conference on Very Large Data Bases",
	Year = 1985,
	Pages = "458--469",
	Annote = "The basic idea is to represent complex objects
		  as terms and to manipulate them using Horn
		  clauses.  His goal is to compile these
		  Horn clauses to an extended relational
		  algebra, so he introduces extend selects
		  and projects (which use Dewey Decimal notation
		  to index into term) and the combine (which
		  combines its arguments into a term.)  Then
		  he shows how to compile these rules into
		  rules in which the heads contain no complex
		  terms.  He says nothing about how these objects
		  are stored, and very little about how ERA is
		  to be implemented.  (He mentions ``selections
		  as filters.'')"}

@unpublished{zyt:ane,
	Author = "W. Zhang and C. T. Yu and D. Troy",
	Title = "A necessary and sufficient condition to linearize doubly
		 recursive programs in logic databases",
	Note = "Unpublished manuscript, Department of EECS, University
	        of Illinois at Chicago",
	Year = 1988}


@inproceedings{cdf:sho,
	Author = "M. Carey, D. DeWitt, M. Franklin, N. Hall, M. McAuliffe, J. Naughton, D. Schuh, M. Solomon, C. Tan, O. Tsatalos, S. White, and M. Zwilling",
	Title = "Shoring Up Persistent Applications",
	Booktitle = "Proceedings of the ACM SIGMOD International Conference
		     on Management of Data",
	Year = 1994,
	Address = "Minneapolis, MN",
	Month = "May",
	Annote = "No note"}
		  
@inproceedings{dns:parset,
	author = "DeWitt, David and Naughton, Jeffrey and Shafer,John and Venkataraman, Shivakumar"
	,title =  "Parsets for Parallelizing OODBMS Traversals:A Performance
		Evaluation"
	,booktitle = "Proceedings of the 3rd International  Conference on
			Parallel and Distributed Information Systems"       
	,month = "September"
	,year =  1994
	,address = "Austin, Texas" }

@inproceedings{vln:imp,
	author = "Shivakumar Venkataraman and Miron Livny and Jeffrey Naughton"
	,title =  "Impact of Declustering on Memory Management for Parallel
		OODBMS"
	,booktitle = "Proceedings of the International Conference on Data
		Engineering"
	,month = "March"
	,year =  1995
	,address = "Taiwan"
	}

@inproceedings{dkl:cli,
	author = "DeWitt, David J. and Kabra, Navin and Luo, Jun and Patel, Jignesh M.  and Yu, Jie-Bing"
	,title =  "Client-Server Paradise"
	,booktitle = "Proceedings of the 20th International Conference on 
	Very Large Databases"
	,month = "September"
	,year =  1994
	,address = "Santiago, Chile"
	,Pages = "558--569"
	}

